{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Set up your environment according to the repo's environment.yml file or run the following...\n",
    "# Comment these out, once installed or otherwise not needed.\n",
    "# This creates an empty pip_requirements.txt file used to suppress 'already satisfied' output.\n",
    "import os\n",
    "with open('pip_requirements.txt', mode='a'): pass\n",
    "%pip install boto3        -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install pandas       -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install numpy        -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install requests     -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install ipywidgets   -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install scikit-learn -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install autogluon    -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install matplotlib   -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install nbconvert    -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install python-dotenv    -r pip_requirements.txt | grep -v 'already satisfied'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements for packages used...\n",
    "import os, glob, shutil, sys, requests, json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from types import SimpleNamespace\n",
    "from IPython.display import clear_output\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # This loads variables from .env into os.environ\n",
    "\n",
    "# Now you can access them\n",
    "api_key = os.getenv('OPENAQ_API_KEY')\n",
    "\n",
    "# The following is required for matplotlib plots to display in some envs...\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes and Variables are ready.\n"
     ]
    }
   ],
   "source": [
    "# class AQParam => Used to define attributes for the (6) main OpenAQ parameters.\n",
    "class AQParam:\n",
    "    def __init__(self, id, name, unit, unhealthyThresholdDefault, desc):\n",
    "        self.id                        = id\n",
    "        self.name                      = name\n",
    "        self.unit                      = unit\n",
    "        self.unhealthyThresholdDefault = unhealthyThresholdDefault\n",
    "        self.desc                      = desc\n",
    "    \n",
    "    def isValid(self):\n",
    "        if(self is not None and self.id > 0 and self.unhealthyThresholdDefault > 0.0 and \n",
    "           len(self.name) > 0 and len(self.unit) > 0 and len(self.desc) > 0):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    def toJSON(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=2)\n",
    "\n",
    "# class AQScenario => Defines an ML scenario including a Location w/ NOAA Weather Station ID \n",
    "#                     and the target OpenAQ Param.\n",
    "# Note: OpenAQ data mostly begins sometime in 2016, so using that as a default yearStart value.\n",
    "class AQScenario:\n",
    "    def __init__(self, location=None, noaaStationID=None, aqParamTarget=None, unhealthyThreshold=None, \n",
    "                 yearStart=2016, yearEnd=2024, aqRadiusMiles=10, featureColumnsToDrop=None):\n",
    "        self.location           = location\n",
    "        self.name               = location + \"_\" + aqParamTarget.name\n",
    "        self.noaaStationID      = noaaStationID\n",
    "        self.noaaStationLat     = 0.0\n",
    "        self.noaaStationLng     = 0.0\n",
    "        self.openAqSensorIDs       = []\n",
    "        \n",
    "        self.aqParamTarget      = aqParamTarget\n",
    "        \n",
    "        if unhealthyThreshold and unhealthyThreshold > 0.0:\n",
    "            self.unhealthyThreshold = unhealthyThreshold\n",
    "        else:\n",
    "            self.unhealthyThreshold = self.aqParamTarget.unhealthyThresholdDefault\n",
    "        \n",
    "        self.yearStart          = yearStart\n",
    "        self.yearEnd            = yearEnd\n",
    "        self.aqRadiusMiles      = aqRadiusMiles\n",
    "        self.aqRadiusMeters     = aqRadiusMiles * 1610 # Rough integer approximation is fine here.\n",
    "        \n",
    "        self.modelFolder        = \"AutogluonModels\"\n",
    "            \n",
    "    def getSummary(self):\n",
    "        return f\"Scenario: {self.name} => {self.aqParamTarget.desc} ({self.aqParamTarget.name}) with UnhealthyThreshold > {self.unhealthyThreshold} {self.aqParamTarget.unit}\"\n",
    "    \n",
    "    def getModelPath(self):\n",
    "        return f\"{self.modelFolder}/aq_{self.name}_{self.yearStart}-{self.yearEnd}/\"\n",
    "    \n",
    "    def updateNoaaStationLatLng(self, noaagsod_df_row):\n",
    "        # Use a NOAA row to set Lat+Lng values used for the OpenAQ API requests...\n",
    "        if(noaagsod_df_row is not None and noaagsod_df_row['LATITUDE'] and noaagsod_df_row['LONGITUDE']):\n",
    "            self.noaaStationLat = noaagsod_df_row['LATITUDE']\n",
    "            self.noaaStationLng = noaagsod_df_row['LONGITUDE']\n",
    "            print(f\"NOAA Station Lat,Lng Updated for Scenario: {self.name} => {self.noaaStationLat},{self.noaaStationLng}\")\n",
    "        else:\n",
    "            print(\"NOAA Station Lat,Lng COULD NOT BE UPDATED.\")\n",
    "    \n",
    "    def isValid(self):\n",
    "        if(self is not None and self.aqParamTarget is not None and\n",
    "           self.yearStart > 0 and self.yearEnd > 0 and self.yearEnd >= self.yearStart and \n",
    "           self.aqRadiusMiles > 0 and self.aqRadiusMeters > 0 and self.unhealthyThreshold > 0.0 and \n",
    "           len(self.name) > 0 and len(self.noaaStationID) > 0):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    def toJSON(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=2)\n",
    "\n",
    "# class AQbyWeatherApp => Main app class with settings, AQParams, AQScenarios, and data access methods...\n",
    "class AQbyWeatherApp:\n",
    "    def __init__(self, mlTargetLabel='isUnhealthy', mlEvalMetric='accuracy', mlTimeLimitSecs=None):\n",
    "        self.mlTargetLabel   = mlTargetLabel\n",
    "        self.mlEvalMetric    = mlEvalMetric\n",
    "        self.mlTimeLimitSecs = mlTimeLimitSecs\n",
    "        self.mlIgnoreColumns = ['DATE','NAME','LATITUDE','LONGITUDE','day','avg']\n",
    "        \n",
    "        self.defaultColumnsNOAA   = ['DATE','NAME','LATITUDE','LONGITUDE',\n",
    "                                     'DEWP','WDSP','MAX','MIN','PRCP','MONTH'] # Default relevant NOAA columns\n",
    "        # self.defaultColumnsOpenAQ = ['summary']       # Default relevant OpenAQ columns\n",
    "        \n",
    "        self.aqParams    = {} # A list to save AQParam objects\n",
    "        self.aqScenarios = {} # A list to save AQScenario objects\n",
    "        \n",
    "        self.selectedScenario = None\n",
    "    \n",
    "    def addAQParam(self, aqParam):\n",
    "        if aqParam and aqParam.isValid():\n",
    "            self.aqParams[aqParam.name] = aqParam\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def addAQScenario(self, aqScenario):\n",
    "        if aqScenario and aqScenario.isValid():\n",
    "            self.aqScenarios[aqScenario.name] = aqScenario\n",
    "            if(self.selectedScenario is None):\n",
    "                self.selectedScenario = self.aqScenarios[next(iter(self.aqScenarios))] # Default selectedScenario to 1st item.\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def getFilenameNOAA(self):\n",
    "        if self and self.selectedScenario and self.selectedScenario.isValid():\n",
    "            return f\"dataNOAA_{self.selectedScenario.name}_{self.selectedScenario.yearStart}-{self.selectedScenario.yearEnd}_{self.selectedScenario.noaaStationID}.csv\"\n",
    "        else:\n",
    "            return \"\"\n",
    "    \n",
    "    def getFilenameOpenAQ(self):\n",
    "        if self and self.selectedScenario and self.selectedScenario.isValid() and len(self.selectedScenario.openAqSensorIDs) > 0:\n",
    "            idString = \"\"\n",
    "            for i in range(0, len(self.selectedScenario.openAqSensorIDs)):\n",
    "                idString = idString + str(self.selectedScenario.openAqSensorIDs[i]) + \"-\"\n",
    "            idString = idString[:-1]\n",
    "            return f\"dataOpenAQ_{self.selectedScenario.name}_{self.selectedScenario.yearStart}-{self.selectedScenario.yearEnd}_{idString}.csv\"\n",
    "        else:\n",
    "            return \"\"\n",
    "    \n",
    "    def getFilenameOther(self, prefix):\n",
    "        if self and self.selectedScenario and self.selectedScenario.isValid():\n",
    "            return f\"{prefix}_{self.selectedScenario.name}_{self.selectedScenario.yearStart}-{self.selectedScenario.yearEnd}.csv\"\n",
    "    \n",
    "    def getNoaaDataFrame(self):\n",
    "        # ASDI Dataset Name: NOAA GSOD\n",
    "        # ASDI Dataset URL : https://registry.opendata.aws/noaa-gsod/\n",
    "        # NOAA GSOD README : https://www.ncei.noaa.gov/data/global-summary-of-the-day/doc/readme.txt\n",
    "        # NOAA GSOD data in S3 is organized by year and Station ID values, so this is straight-forward\n",
    "        # Example S3 path format => s3://noaa-gsod-pds/{yyyy}/{stationid}.csv\n",
    "        # Let's start with a new DataFrame and load it from a local CSV or the NOAA data source...\n",
    "        noaagsod_df = pd.DataFrame()\n",
    "        filenameNOAA = self.getFilenameNOAA()\n",
    "\n",
    "        if os.path.exists(filenameNOAA):\n",
    "            # Use local data file already accessed + prepared...\n",
    "            print('Loading NOAA GSOD data from local file: ', filenameNOAA)\n",
    "            noaagsod_df = pd.read_csv(filenameNOAA)\n",
    "        else:\n",
    "            # Access + prepare data and save to a local data file...\n",
    "            noaagsod_bucket = 'noaa-gsod-pds'\n",
    "            print(f'Accessing and preparing data from ASDI-hosted NOAA GSOD dataset in Amazon S3 (bucket: {noaagsod_bucket})...')\n",
    "            s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "            for year in range(self.selectedScenario.yearStart, self.selectedScenario.yearEnd + 1):\n",
    "                key = f'{year}/{self.selectedScenario.noaaStationID}.csv'                                    # Compute the key to get\n",
    "                csv_obj = s3.get_object(Bucket=noaagsod_bucket, Key=key)                                     # Get the S3 object\n",
    "                csv_string = csv_obj['Body'].read().decode('utf-8')                                          # Read object contents to a string\n",
    "                noaagsod_df = pd.concat([noaagsod_df, pd.read_csv(StringIO(csv_string))], ignore_index=True) # Use the string to build the DataFrame\n",
    "\n",
    "            # It may be true that Month affects air quality (ie: seasonal considerations; tends to have correlation for certain areas)\n",
    "            # Extract date components for seasonality\n",
    "            noaagsod_df['MONTH'] = pd.to_datetime(noaagsod_df['DATE']).dt.month\n",
    "            noaagsod_df['DAYOFWEEK'] = pd.to_datetime(noaagsod_df['DATE']).dt.dayofweek\n",
    "            noaagsod_df['SEASON'] = pd.to_datetime(noaagsod_df['DATE']).dt.month.map({1: 'Winter', 2: 'Winter', 3: 'Spring', \n",
    "                                                                                      4: 'Spring', 5: 'Spring', 6: 'Summer',\n",
    "                                                                                      7: 'Summer', 8: 'Summer', 9: 'Fall', \n",
    "                                                                                      10: 'Fall', 11: 'Fall', 12: 'Winter'})\n",
    "            \n",
    "            # Calculate temperature differences and averages\n",
    "            noaagsod_df['TEMP_RANGE'] = noaagsod_df['MAX'] - noaagsod_df['MIN']\n",
    "            noaagsod_df['TEMP_AVG'] = (noaagsod_df['MAX'] + noaagsod_df['MIN']) / 2\n",
    "            \n",
    "            # Create interaction features\n",
    "            noaagsod_df['TEMP_DEWP_DIFF'] = noaagsod_df['TEMP_AVG'] - noaagsod_df['DEWP']\n",
    "            noaagsod_df['WDSP_TEMP'] = noaagsod_df['WDSP'] * noaagsod_df['TEMP_AVG']\n",
    "\n",
    "            # Trim down to the desired key columns... (do this last in case engineered columns are to be removed)\n",
    "            # noaagsod_df = noaagsod_df[self.defaultColumnsNOAA]\n",
    "            \n",
    "        return noaagsod_df\n",
    "        \n",
    "    def getOpenAqDataFrame(self):\n",
    "        # ASDI Dataset Name: OpenAQ\n",
    "        # ASDI Dataset URL : https://registry.opendata.aws/openaq/\n",
    "        # OpenAQ API Docs  : https://docs.openaq.org/\n",
    "        # OpenAQ S3 data is only organized by date folders, so each folder is large and contains all stations.\n",
    "        # Because of this, it's better to query ASDI OpenAQ data using the CloudFront-hosted API.\n",
    "        # Note that some days may not have values and will get filtered out via an INNER JOIN later.\n",
    "        # Let's start with a new DataFrame and load it from a local CSV or the NOAA data source...\n",
    "        aq_df = pd.DataFrame()\n",
    "        aq_reqUrlBase = \"https://api.openaq.org/v3\" # OpenAQ ASDI API Endpoint URL Base\n",
    "        print(f\"API Key: {api_key}\")\n",
    "        headers = {\n",
    "            'accept': 'application/json',\n",
    "            'x-api-key': api_key\n",
    "        }\n",
    "\n",
    "        if self.selectedScenario.noaaStationLat == 0.0 or self.selectedScenario.noaaStationLng == 0.0:\n",
    "            print(\"NOAA Station Lat/Lng NOT DEFINED. CANNOT PROCEED\")\n",
    "            return aq_df\n",
    "        \n",
    "        if len(self.selectedScenario.openAqSensorIDs) == 0:\n",
    "            # Find OpenAQ sensors near the NOAA station location\n",
    "            print('Finding OpenAQ sensors near NOAA station location...')\n",
    "            \n",
    "            # Query OpenAQ locations API with coordinates\n",
    "            aq_reqParams = {\n",
    "                'coordinates': f\"{self.selectedScenario.noaaStationLat},{self.selectedScenario.noaaStationLng}\",\n",
    "                'radius': 25000, # 25km radius\n",
    "                'parameter': self.selectedScenario.aqParamTarget.name,\n",
    "                'limit': 100\n",
    "            }\n",
    "            \n",
    "            aq_resp = requests.get(aq_reqUrlBase + \"/locations\", params=aq_reqParams, headers=headers)\n",
    "            aq_data = aq_resp.json()\n",
    "            \n",
    "            if 'results' in aq_data:\n",
    "                for location in aq_data['results']:\n",
    "                    # Check each location's sensors for our target parameter\n",
    "                    for sensor in location['sensors']:\n",
    "                        if sensor['parameter']['name'] == self.selectedScenario.aqParamTarget.name:\n",
    "                            self.selectedScenario.openAqSensorIDs.append(sensor['id'])\n",
    "                            break # Only need one sensor per location\n",
    "                            \n",
    "            print(f'Found {len(self.selectedScenario.openAqSensorIDs)} OpenAQ locations with {self.selectedScenario.aqParamTarget.name} sensors')\n",
    "        \n",
    "        if len(self.selectedScenario.openAqSensorIDs) >= 1:\n",
    "            filenameOpenAQ = self.getFilenameOpenAQ()\n",
    "\n",
    "            if os.path.exists(filenameOpenAQ):\n",
    "                # Use local data file already accessed + prepared...\n",
    "                print('Loading OpenAQ data from local file: ', filenameOpenAQ)\n",
    "                aq_df = pd.read_csv(filenameOpenAQ)\n",
    "            else:\n",
    "                # Access + prepare data (NOTE: calling OpenAQ API one year at a time to avoid timeouts)\n",
    "                print('Accessing ASDI-hosted OpenAQ Measurements (HTTPS API)...')\n",
    "                \n",
    "                for year in range(self.selectedScenario.yearStart, self.selectedScenario.yearEnd + 1):\n",
    "                    for sensor_id in self.selectedScenario.openAqSensorIDs:\n",
    "                        # Get daily measurements for this sensor and year\n",
    "                        aq_reqUrl = f\"{aq_reqUrlBase}/sensors/{sensor_id}/days\"\n",
    "                        aq_reqParams = {\n",
    "                            'date_from': f'{year}-01-01',\n",
    "                            'date_to': f'{year}-12-31',\n",
    "                            'limit': 366\n",
    "                        }\n",
    "                        \n",
    "                        print(f'Fetching data for sensor {sensor_id} in {year}')\n",
    "                        aq_resp = requests.get(aq_reqUrl, params=aq_reqParams, headers=headers)\n",
    "                        aq_data = aq_resp.json()\n",
    "                        \n",
    "                        if 'results' in aq_data:\n",
    "                            for measurement in aq_data['results']:\n",
    "                                dt = datetime.strptime(measurement['period']['datetimeFrom']['utc'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                                if measurement['value'] is not None:\n",
    "                                    date_df = pd.DataFrame({'day': [dt.date()], 'avg': [measurement['value']]})\n",
    "                                    aq_df = pd.concat([aq_df, date_df], ignore_index=True)\n",
    "\n",
    "                # Group by day and calculate daily averages\n",
    "                if not aq_df.empty:\n",
    "                    aq_df = aq_df.groupby('day')['avg'].mean().reset_index()\n",
    "\n",
    "                # Perform some Label Engineering to add our binary classification label => {0=OKAY, 1=UNHEALTHY}\n",
    "                if not aq_df.empty:\n",
    "                    aq_df[self.mlTargetLabel] = np.where(aq_df['avg'] <= self.selectedScenario.unhealthyThreshold, 0, 1)\n",
    "        \n",
    "        return aq_df\n",
    "    \n",
    "    def getMergedDataFrame(self, noaagsod_df, aq_df):\n",
    "        if len(noaagsod_df) > 0 and len(aq_df) > 0:\n",
    "            # Print shapes before merge to debug\n",
    "            print(f\"NOAA GSOD shape before merge: {noaagsod_df.shape}\")\n",
    "            print(f\"AQ data shape before merge: {aq_df.shape}\")\n",
    "            print(\"\\nNOAA GSOD sample:\")\n",
    "            print(noaagsod_df.head())\n",
    "            print(\"\\nAQ data sample:\")\n",
    "            print(aq_df.head())\n",
    "            \n",
    "            merged_df = pd.merge(noaagsod_df, aq_df, how=\"inner\", left_on=\"DATE\", right_on=\"day\")\n",
    "            \n",
    "            # Print shape after merge to see if rows were lost\n",
    "            print(f\"\\nMerged shape: {merged_df.shape}\")\n",
    "            \n",
    "            if len(merged_df) == 0:\n",
    "                print(\"\\nMerge resulted in empty DataFrame. This means there are no matching dates between the two datasets.\")\n",
    "                print(\"Check that DATE and day columns have the same format (both should be datetime or string)\")\n",
    "                print(f\"DATE dtype: {noaagsod_df['DATE'].dtype}\")\n",
    "                print(f\"day dtype: {aq_df['day'].dtype}\")\n",
    "            \n",
    "            display(merged_df)\n",
    "            merged_df = merged_df.drop(columns=self.mlIgnoreColumns)\n",
    "            return merged_df\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def getConfusionMatrixData(self, cm):\n",
    "        cmData = SimpleNamespace()\n",
    "        cmData.TN = cm[0][0]\n",
    "        cmData.TP = cm[1][1]\n",
    "        cmData.FN = cm[1][0]\n",
    "        cmData.FP = cm[0][1]\n",
    "        \n",
    "        cmData.TN_Rate = cmData.TN/(cmData.TN+cmData.FP)\n",
    "        cmData.TP_Rate = cmData.TP/(cmData.TP+cmData.FN)\n",
    "        cmData.FN_Rate = cmData.FN/(cmData.FN+cmData.TP)\n",
    "        cmData.FP_Rate = cmData.FP/(cmData.FP+cmData.TN)\n",
    "        \n",
    "        cmData.TN_Output = f\"True Negatives  (TN): {cmData.TN} of {cmData.TN+cmData.FP} => {round(cmData.TN_Rate * 100, 2)}%\"\n",
    "        cmData.TP_Output = f\"True Positives  (TP): {cmData.TP} of {cmData.TP+cmData.FN} => {round(cmData.TP_Rate * 100, 2)}%\"\n",
    "        cmData.FN_Output = f\"False Negatives (FN): {cmData.FN} of {cmData.FN+cmData.TP} => {round(cmData.FN_Rate * 100, 2)}%\"\n",
    "        cmData.FP_Output = f\"False Positives (FP): {cmData.FP} of {cmData.FP+cmData.TN} => {round(cmData.FP_Rate * 100, 2)}%\"\n",
    "        \n",
    "        return cmData\n",
    "            \n",
    "print(\"Classes and Variables are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQbyWeather.aqParams: 6\n",
      "AQbyWeather.aqScenarios: 15 (Default Selected: bakersfield_pm25)\n"
     ]
    }
   ],
   "source": [
    "# CELL #4: Review the pre-defined AQParams and AQScenarios in this cell. You can edit these and/or use your own...\n",
    "# AQParams are added with default thresholds, which can be overridden on a per-AQScenario basis.\n",
    "# These AQParams are based on the OpenAQ /parameters API call where isCore=true (https://api.openaq.org/v2/parameters).\n",
    "# Default thresholds where provided using data from EPA.gov (https://www.epa.gov/criteria-air-pollutants/naaqs-table).\n",
    "# Confirm and adjust params or thresholds as needed for your needs... Not for scientific or health purposes.\n",
    "\n",
    "# Instantiate main App class with explicit mlTargetLabel and mlEvalMetric provided...\n",
    "AQbyWeather = AQbyWeatherApp(mlTargetLabel='isUnhealthy', mlEvalMetric='accuracy', mlTimeLimitSecs=120)\n",
    "\n",
    "# Define and add new AQParams...\n",
    "AQbyWeather.addAQParam(AQParam( 1, \"pm10\", \"µg/m³\", 150.0, \"Particulate Matter < 10 micrometers\"))\n",
    "AQbyWeather.addAQParam(AQParam( 2, \"pm25\", \"µg/m³\",  12.0, \"Particulate Matter < 2.5 micrometers\"))\n",
    "AQbyWeather.addAQParam(AQParam( 7, \"no2\",  \"ppm\",   100.0, \"Nitrogen Dioxide\"))\n",
    "AQbyWeather.addAQParam(AQParam( 8, \"co\",   \"ppm\",     9.0, \"Carbon Monoxide\"))\n",
    "AQbyWeather.addAQParam(AQParam( 9, \"so2\",  \"ppm\",    75.0, \"Sulfur Dioxide\"))\n",
    "AQbyWeather.addAQParam(AQParam(10, \"o3\",   \"ppm\",   0.070, \"Ground Level Ozone\"))\n",
    "\n",
    "# Define available AQ Scenarios for certain locations with their associated NOAA GSOD StationID values...\n",
    "# NOAA GSOD Station Search: https://www.ncei.noaa.gov/access/search/data-search/global-summary-of-the-day\n",
    "# TODO: Someday consider how to OPTIONALLY append more scenarios via an optional JSON file\n",
    "#       (ie: without adding a dependecy outside the .ipynb file)\n",
    "# NOTE: For Ozone Scenarios, we're generally using 0.035 ppm to override the default threshold.\n",
    "AQbyWeather.addAQScenario(AQScenario(\"bakersfield\", \"72384023155\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"bakersfield\", \"72384023155\", AQbyWeather.aqParams[\"pm10\"], None)) # Attempt at pm10 prediction.\n",
    "AQbyWeather.addAQScenario(AQScenario(\"bakersfield\", \"72384023155\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"fresno\",      \"72389093193\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"fresno\",      \"72389093193\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"visalia\",     \"72389693144\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"visalia\",     \"72389693144\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"san-jose\",    \"72494693232\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"san-jose\",    \"72494693232\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"los-angeles\", \"72287493134\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"los-angeles\", \"72287493134\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"phoenix\",     \"72278023183\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"phoenix\",     \"72278023183\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"fairbanks\",   \"70261026411\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"lahore-pk\",   \"41640099999\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "\n",
    "print(f\"AQbyWeather.aqParams: {str(len(AQbyWeather.aqParams))}\")\n",
    "print(f\"AQbyWeather.aqScenarios: {str(len(AQbyWeather.aqScenarios))} (Default Selected: {AQbyWeather.selectedScenario.name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** CHOOSE YOUR OWN ADVENTURE HERE ***\n",
      "Please select a Scenario via the following drop-down-list...\n",
      "(NOTE: If you change Scenario, you must re-run remaining cells to see changes.)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bf8de8bac7472fb89c56923bb5db4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(index=9, options=('bakersfield_pm25', 'bakersfield_pm10', 'bakersfield_o3', 'fresno_pm25', 'fresno_o3…"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELL #5: Select a Scenario via DROP DOWN LIST to use throughout the Notebook. This will drive the ML process...\n",
    "# A default \"value\" is set to avoid issues. Change this default to run the Notebook from start-to-finish for that Scenario.\n",
    "print(\"*** CHOOSE YOUR OWN ADVENTURE HERE ***\")\n",
    "print(\"Please select a Scenario via the following drop-down-list...\")\n",
    "print(\"(NOTE: If you change Scenario, you must re-run remaining cells to see changes.)\")\n",
    "ddl = widgets.Dropdown(options=AQbyWeather.aqScenarios.keys(), \n",
    "                       value=AQbyWeather.aqScenarios[\"los-angeles_pm25\"].name) # <-- DEFAULT / FULL-RUN VALUE\n",
    "ddl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario: los-angeles_pm25 => Particulate Matter < 2.5 micrometers (pm25) with UnhealthyThreshold > 12.0 µg/m³\n",
      "{\n",
      "  \"aqParamTarget\": {\n",
      "    \"desc\": \"Particulate Matter < 2.5 micrometers\",\n",
      "    \"id\": 2,\n",
      "    \"name\": \"pm25\",\n",
      "    \"unhealthyThresholdDefault\": 12.0,\n",
      "    \"unit\": \"\\u00b5g/m\\u00b3\"\n",
      "  },\n",
      "  \"aqRadiusMeters\": 16100,\n",
      "  \"aqRadiusMiles\": 10,\n",
      "  \"location\": \"los-angeles\",\n",
      "  \"modelFolder\": \"AutogluonModels\",\n",
      "  \"name\": \"los-angeles_pm25\",\n",
      "  \"noaaStationID\": \"72287493134\",\n",
      "  \"noaaStationLat\": 0.0,\n",
      "  \"noaaStationLng\": 0.0,\n",
      "  \"openAqSensorIDs\": [],\n",
      "  \"unhealthyThreshold\": 12.0,\n",
      "  \"yearEnd\": 2024,\n",
      "  \"yearStart\": 2016\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if ddl.value:\n",
    "    AQbyWeather.selectedScenario = AQbyWeather.aqScenarios[ddl.value]\n",
    "    print(AQbyWeather.selectedScenario.getSummary())\n",
    "    print(AQbyWeather.selectedScenario.toJSON())\n",
    "else:\n",
    "    print(\"Please select a Scenario via the above drop-down-list.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario: los-angeles_pm25 => Particulate Matter < 2.5 micrometers (pm25) with UnhealthyThreshold > 12.0 µg/m³\n",
      "Loading NOAA GSOD data from local file:  dataNOAA_los-angeles_pm25_2016-2024_72287493134.csv\n",
      "NOAA Station Lat,Lng Updated for Scenario: los-angeles_pm25 => 34.0236,-118.2911\n",
      "noaagsod_df.shape = (3061, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>TEMP_ATTRIBUTES</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>DEWP_ATTRIBUTES</th>\n",
       "      <th>...</th>\n",
       "      <th>PRCP_ATTRIBUTES</th>\n",
       "      <th>SNDP</th>\n",
       "      <th>FRSHTT</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAYOFWEEK</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEMP_RANGE</th>\n",
       "      <th>TEMP_AVG</th>\n",
       "      <th>TEMP_DEWP_DIFF</th>\n",
       "      <th>WDSP_TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72287493134</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>34.0236</td>\n",
       "      <td>-118.2911</td>\n",
       "      <td>54.6</td>\n",
       "      <td>LOS ANGELES DOWNTOWN USC, CA US</td>\n",
       "      <td>52.7</td>\n",
       "      <td>24</td>\n",
       "      <td>19.1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>999.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Winter</td>\n",
       "      <td>23.9</td>\n",
       "      <td>52.95</td>\n",
       "      <td>33.85</td>\n",
       "      <td>84.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72287493134</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>34.0236</td>\n",
       "      <td>-118.2911</td>\n",
       "      <td>54.6</td>\n",
       "      <td>LOS ANGELES DOWNTOWN USC, CA US</td>\n",
       "      <td>54.8</td>\n",
       "      <td>24</td>\n",
       "      <td>20.1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>999.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Winter</td>\n",
       "      <td>21.9</td>\n",
       "      <td>53.95</td>\n",
       "      <td>33.85</td>\n",
       "      <td>113.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72287493134</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>34.0236</td>\n",
       "      <td>-118.2911</td>\n",
       "      <td>54.6</td>\n",
       "      <td>LOS ANGELES DOWNTOWN USC, CA US</td>\n",
       "      <td>52.6</td>\n",
       "      <td>24</td>\n",
       "      <td>38.2</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>999.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Winter</td>\n",
       "      <td>20.8</td>\n",
       "      <td>54.50</td>\n",
       "      <td>16.30</td>\n",
       "      <td>38.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72287493134</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>34.0236</td>\n",
       "      <td>-118.2911</td>\n",
       "      <td>54.6</td>\n",
       "      <td>LOS ANGELES DOWNTOWN USC, CA US</td>\n",
       "      <td>59.3</td>\n",
       "      <td>24</td>\n",
       "      <td>44.1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>999.9</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>25.0</td>\n",
       "      <td>56.60</td>\n",
       "      <td>12.50</td>\n",
       "      <td>62.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72287493134</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>34.0236</td>\n",
       "      <td>-118.2911</td>\n",
       "      <td>54.6</td>\n",
       "      <td>LOS ANGELES DOWNTOWN USC, CA US</td>\n",
       "      <td>57.4</td>\n",
       "      <td>24</td>\n",
       "      <td>51.9</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>999.9</td>\n",
       "      <td>110000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>15.1</td>\n",
       "      <td>61.55</td>\n",
       "      <td>9.65</td>\n",
       "      <td>129.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>72287493134</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>34.0236</td>\n",
       "      <td>-118.2911</td>\n",
       "      <td>54.6</td>\n",
       "      <td>LOS ANGELES DOWNTOWN USC, CA US</td>\n",
       "      <td>62.9</td>\n",
       "      <td>24</td>\n",
       "      <td>53.2</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>999.9</td>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Spring</td>\n",
       "      <td>7.9</td>\n",
       "      <td>64.05</td>\n",
       "      <td>10.85</td>\n",
       "      <td>51.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>72287493134</td>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>34.0236</td>\n",
       "      <td>-118.2911</td>\n",
       "      <td>54.6</td>\n",
       "      <td>LOS ANGELES DOWNTOWN USC, CA US</td>\n",
       "      <td>63.2</td>\n",
       "      <td>24</td>\n",
       "      <td>53.8</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>999.9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Spring</td>\n",
       "      <td>9.0</td>\n",
       "      <td>64.60</td>\n",
       "      <td>10.80</td>\n",
       "      <td>58.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>72287493134</td>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>34.0236</td>\n",
       "      <td>-118.2911</td>\n",
       "      <td>54.6</td>\n",
       "      <td>LOS ANGELES DOWNTOWN USC, CA US</td>\n",
       "      <td>62.9</td>\n",
       "      <td>24</td>\n",
       "      <td>53.5</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>999.9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Spring</td>\n",
       "      <td>10.1</td>\n",
       "      <td>64.05</td>\n",
       "      <td>10.55</td>\n",
       "      <td>83.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>72287493134</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>34.0236</td>\n",
       "      <td>-118.2911</td>\n",
       "      <td>54.6</td>\n",
       "      <td>LOS ANGELES DOWNTOWN USC, CA US</td>\n",
       "      <td>62.9</td>\n",
       "      <td>24</td>\n",
       "      <td>52.1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>999.9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Spring</td>\n",
       "      <td>13.0</td>\n",
       "      <td>65.50</td>\n",
       "      <td>13.40</td>\n",
       "      <td>91.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>72287493134</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>34.0236</td>\n",
       "      <td>-118.2911</td>\n",
       "      <td>54.6</td>\n",
       "      <td>LOS ANGELES DOWNTOWN USC, CA US</td>\n",
       "      <td>59.9</td>\n",
       "      <td>15</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>999.9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.50</td>\n",
       "      <td>12.50</td>\n",
       "      <td>83.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3061 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          STATION        DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
       "0     72287493134  2016-01-01   34.0236  -118.2911       54.6   \n",
       "1     72287493134  2016-01-02   34.0236  -118.2911       54.6   \n",
       "2     72287493134  2016-01-03   34.0236  -118.2911       54.6   \n",
       "3     72287493134  2016-01-04   34.0236  -118.2911       54.6   \n",
       "4     72287493134  2016-01-05   34.0236  -118.2911       54.6   \n",
       "...           ...         ...       ...        ...        ...   \n",
       "3056  72287493134  2024-05-16   34.0236  -118.2911       54.6   \n",
       "3057  72287493134  2024-05-17   34.0236  -118.2911       54.6   \n",
       "3058  72287493134  2024-05-18   34.0236  -118.2911       54.6   \n",
       "3059  72287493134  2024-05-19   34.0236  -118.2911       54.6   \n",
       "3060  72287493134  2024-05-20   34.0236  -118.2911       54.6   \n",
       "\n",
       "                                 NAME  TEMP  TEMP_ATTRIBUTES  DEWP  \\\n",
       "0     LOS ANGELES DOWNTOWN USC, CA US  52.7               24  19.1   \n",
       "1     LOS ANGELES DOWNTOWN USC, CA US  54.8               24  20.1   \n",
       "2     LOS ANGELES DOWNTOWN USC, CA US  52.6               24  38.2   \n",
       "3     LOS ANGELES DOWNTOWN USC, CA US  59.3               24  44.1   \n",
       "4     LOS ANGELES DOWNTOWN USC, CA US  57.4               24  51.9   \n",
       "...                               ...   ...              ...   ...   \n",
       "3056  LOS ANGELES DOWNTOWN USC, CA US  62.9               24  53.2   \n",
       "3057  LOS ANGELES DOWNTOWN USC, CA US  63.2               24  53.8   \n",
       "3058  LOS ANGELES DOWNTOWN USC, CA US  62.9               24  53.5   \n",
       "3059  LOS ANGELES DOWNTOWN USC, CA US  62.9               24  52.1   \n",
       "3060  LOS ANGELES DOWNTOWN USC, CA US  59.9               15  52.0   \n",
       "\n",
       "      DEWP_ATTRIBUTES  ...  PRCP_ATTRIBUTES   SNDP  FRSHTT  MONTH  DAYOFWEEK  \\\n",
       "0                  24  ...                G  999.9       0      1          4   \n",
       "1                  24  ...                G  999.9       0      1          5   \n",
       "2                  24  ...                G  999.9       0      1          6   \n",
       "3                  24  ...                G  999.9   10000      1          0   \n",
       "4                  24  ...                G  999.9  110000      1          1   \n",
       "...               ...  ...              ...    ...     ...    ...        ...   \n",
       "3056               24  ...                G  999.9   10000      5          3   \n",
       "3057               24  ...                G  999.9       0      5          4   \n",
       "3058               24  ...                G  999.9       0      5          5   \n",
       "3059               24  ...                G  999.9       0      5          6   \n",
       "3060               15  ...                G  999.9       0      5          0   \n",
       "\n",
       "      SEASON  TEMP_RANGE  TEMP_AVG  TEMP_DEWP_DIFF  WDSP_TEMP  \n",
       "0     Winter        23.9     52.95           33.85     84.720  \n",
       "1     Winter        21.9     53.95           33.85    113.295  \n",
       "2     Winter        20.8     54.50           16.30     38.150  \n",
       "3     Winter        25.0     56.60           12.50     62.260  \n",
       "4     Winter        15.1     61.55            9.65    129.255  \n",
       "...      ...         ...       ...             ...        ...  \n",
       "3056  Spring         7.9     64.05           10.85     51.240  \n",
       "3057  Spring         9.0     64.60           10.80     58.140  \n",
       "3058  Spring        10.1     64.05           10.55     83.265  \n",
       "3059  Spring        13.0     65.50           13.40     91.700  \n",
       "3060  Spring        15.0     64.50           12.50     83.850  \n",
       "\n",
       "[3061 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GET NOAA GSOD WEATHER DATA...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "noaagsod_df = AQbyWeather.getNoaaDataFrame()\n",
    "\n",
    "if(len(noaagsod_df) >= 1):\n",
    "    # Update NOAA Station Lat/Lng...\n",
    "    AQbyWeather.selectedScenario.updateNoaaStationLatLng(noaagsod_df.iloc[0])\n",
    "    \n",
    "    # Save DataFrame to CSV...\n",
    "    noaagsod_df.to_csv(AQbyWeather.getFilenameNOAA(), index=False)\n",
    "\n",
    "    # Output DataFrame properties...\n",
    "    print('noaagsod_df.shape =', noaagsod_df.shape)\n",
    "    display(noaagsod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario: los-angeles_pm25 => Particulate Matter < 2.5 micrometers (pm25) with UnhealthyThreshold > 12.0 µg/m³\n",
      "API Key: 49c492bb9d9e24d5e78ae75b2034430080bc132bcd7c9dfa3f2b08fabda35a9d\n",
      "Finding OpenAQ sensors near NOAA station location...\n",
      "Found 90 OpenAQ locations with pm25 sensors\n",
      "Accessing ASDI-hosted OpenAQ Measurements (HTTPS API)...\n",
      "Fetching data for sensor 2775 in 2016\n",
      "Fetching data for sensor 25551 in 2016\n",
      "Fetching data for sensor 15731 in 2016\n",
      "Fetching data for sensor 25196 in 2016\n",
      "Fetching data for sensor 24000 in 2016\n",
      "Fetching data for sensor 1654141 in 2016\n",
      "Fetching data for sensor 1654143 in 2016\n",
      "Fetching data for sensor 1654156 in 2016\n",
      "Fetching data for sensor 1654168 in 2016\n",
      "Fetching data for sensor 1654191 in 2016\n",
      "Fetching data for sensor 2000869 in 2016\n",
      "Fetching data for sensor 1654217 in 2016\n",
      "Fetching data for sensor 2000834 in 2016\n",
      "Fetching data for sensor 1654333 in 2016\n",
      "Fetching data for sensor 1654360 in 2016\n",
      "Fetching data for sensor 2000475 in 2016\n",
      "Fetching data for sensor 2000731 in 2016\n",
      "Fetching data for sensor 2000674 in 2016\n",
      "Fetching data for sensor 1654499 in 2016\n",
      "Fetching data for sensor 1654545 in 2016\n",
      "Fetching data for sensor 1654577 in 2016\n",
      "Fetching data for sensor 1654556 in 2016\n",
      "Fetching data for sensor 1654629 in 2016\n",
      "Fetching data for sensor 2000900 in 2016\n",
      "Fetching data for sensor 1999896 in 2016\n",
      "Fetching data for sensor 2001073 in 2016\n",
      "Fetching data for sensor 2001289 in 2016\n",
      "Fetching data for sensor 2001343 in 2016\n",
      "Fetching data for sensor 2088604 in 2016\n",
      "Fetching data for sensor 2088548 in 2016\n",
      "Fetching data for sensor 2088589 in 2016\n",
      "Fetching data for sensor 2000821 in 2016\n",
      "Fetching data for sensor 2000905 in 2016\n",
      "Fetching data for sensor 2000768 in 2016\n",
      "Fetching data for sensor 2000525 in 2016\n",
      "Fetching data for sensor 2000753 in 2016\n",
      "Fetching data for sensor 2000561 in 2016\n",
      "Fetching data for sensor 2000676 in 2016\n",
      "Fetching data for sensor 2001076 in 2016\n",
      "Fetching data for sensor 2000935 in 2016\n",
      "Fetching data for sensor 2000945 in 2016\n",
      "Fetching data for sensor 2000750 in 2016\n",
      "Fetching data for sensor 2001039 in 2016\n",
      "Fetching data for sensor 2000499 in 2016\n",
      "Fetching data for sensor 2000798 in 2016\n",
      "Fetching data for sensor 2000553 in 2016\n",
      "Fetching data for sensor 2000565 in 2016\n",
      "Fetching data for sensor 2000718 in 2016\n",
      "Fetching data for sensor 2000977 in 2016\n",
      "Fetching data for sensor 2000505 in 2016\n",
      "Fetching data for sensor 2000853 in 2016\n",
      "Fetching data for sensor 2000522 in 2016\n",
      "Fetching data for sensor 2000723 in 2016\n",
      "Fetching data for sensor 2000819 in 2016\n",
      "Fetching data for sensor 2000729 in 2016\n",
      "Fetching data for sensor 2001006 in 2016\n",
      "Fetching data for sensor 2000981 in 2016\n",
      "Fetching data for sensor 2000667 in 2016\n",
      "Fetching data for sensor 2000840 in 2016\n",
      "Fetching data for sensor 2000567 in 2016\n",
      "Fetching data for sensor 2000963 in 2016\n",
      "Fetching data for sensor 2000537 in 2016\n",
      "Fetching data for sensor 2000471 in 2016\n",
      "Fetching data for sensor 2001038 in 2016\n",
      "Fetching data for sensor 2000956 in 2016\n",
      "Fetching data for sensor 2000694 in 2016\n",
      "Fetching data for sensor 2000953 in 2016\n",
      "Fetching data for sensor 2000629 in 2016\n",
      "Fetching data for sensor 2000671 in 2016\n",
      "Fetching data for sensor 2000967 in 2016\n",
      "Fetching data for sensor 2000999 in 2016\n",
      "Fetching data for sensor 2000660 in 2016\n",
      "Fetching data for sensor 2001013 in 2016\n",
      "Fetching data for sensor 2000613 in 2016\n",
      "Fetching data for sensor 2000483 in 2016\n",
      "Fetching data for sensor 2000550 in 2016\n",
      "Fetching data for sensor 2000832 in 2016\n",
      "Fetching data for sensor 2000796 in 2016\n",
      "Fetching data for sensor 2000934 in 2016\n",
      "Fetching data for sensor 2001040 in 2016\n",
      "Fetching data for sensor 2000838 in 2016\n",
      "Fetching data for sensor 2001062 in 2016\n",
      "Fetching data for sensor 2000933 in 2016\n",
      "Fetching data for sensor 2000443 in 2016\n",
      "Fetching data for sensor 2000993 in 2016\n",
      "Fetching data for sensor 2000942 in 2016\n",
      "Fetching data for sensor 2000852 in 2016\n",
      "Fetching data for sensor 2000445 in 2016\n",
      "Fetching data for sensor 2001033 in 2016\n",
      "Fetching data for sensor 2000984 in 2016\n",
      "Fetching data for sensor 2775 in 2017\n",
      "Fetching data for sensor 25551 in 2017\n",
      "Fetching data for sensor 15731 in 2017\n",
      "Fetching data for sensor 25196 in 2017\n",
      "Fetching data for sensor 24000 in 2017\n",
      "Fetching data for sensor 1654141 in 2017\n",
      "Fetching data for sensor 1654143 in 2017\n",
      "Fetching data for sensor 1654156 in 2017\n",
      "Fetching data for sensor 1654168 in 2017\n",
      "Fetching data for sensor 1654191 in 2017\n",
      "Fetching data for sensor 2000869 in 2017\n",
      "Fetching data for sensor 1654217 in 2017\n",
      "Fetching data for sensor 2000834 in 2017\n",
      "Fetching data for sensor 1654333 in 2017\n",
      "Fetching data for sensor 1654360 in 2017\n",
      "Fetching data for sensor 2000475 in 2017\n",
      "Fetching data for sensor 2000731 in 2017\n",
      "Fetching data for sensor 2000674 in 2017\n",
      "Fetching data for sensor 1654499 in 2017\n",
      "Fetching data for sensor 1654545 in 2017\n",
      "Fetching data for sensor 1654577 in 2017\n",
      "Fetching data for sensor 1654556 in 2017\n",
      "Fetching data for sensor 1654629 in 2017\n",
      "Fetching data for sensor 2000900 in 2017\n",
      "Fetching data for sensor 1999896 in 2017\n",
      "Fetching data for sensor 2001073 in 2017\n",
      "Fetching data for sensor 2001289 in 2017\n",
      "Fetching data for sensor 2001343 in 2017\n",
      "Fetching data for sensor 2088604 in 2017\n",
      "Fetching data for sensor 2088548 in 2017\n",
      "Fetching data for sensor 2088589 in 2017\n",
      "Fetching data for sensor 2000821 in 2017\n",
      "Fetching data for sensor 2000905 in 2017\n",
      "Fetching data for sensor 2000768 in 2017\n",
      "Fetching data for sensor 2000525 in 2017\n",
      "Fetching data for sensor 2000753 in 2017\n",
      "Fetching data for sensor 2000561 in 2017\n",
      "Fetching data for sensor 2000676 in 2017\n",
      "Fetching data for sensor 2001076 in 2017\n",
      "Fetching data for sensor 2000935 in 2017\n",
      "Fetching data for sensor 2000945 in 2017\n",
      "Fetching data for sensor 2000750 in 2017\n",
      "Fetching data for sensor 2001039 in 2017\n",
      "Fetching data for sensor 2000499 in 2017\n",
      "Fetching data for sensor 2000798 in 2017\n",
      "Fetching data for sensor 2000553 in 2017\n",
      "Fetching data for sensor 2000565 in 2017\n",
      "Fetching data for sensor 2000718 in 2017\n",
      "Fetching data for sensor 2000977 in 2017\n",
      "Fetching data for sensor 2000505 in 2017\n",
      "Fetching data for sensor 2000853 in 2017\n",
      "Fetching data for sensor 2000522 in 2017\n",
      "Fetching data for sensor 2000723 in 2017\n",
      "Fetching data for sensor 2000819 in 2017\n",
      "Fetching data for sensor 2000729 in 2017\n",
      "Fetching data for sensor 2001006 in 2017\n",
      "Fetching data for sensor 2000981 in 2017\n",
      "Fetching data for sensor 2000667 in 2017\n",
      "Fetching data for sensor 2000840 in 2017\n",
      "Fetching data for sensor 2000567 in 2017\n",
      "Fetching data for sensor 2000963 in 2017\n",
      "Fetching data for sensor 2000537 in 2017\n",
      "Fetching data for sensor 2000471 in 2017\n",
      "Fetching data for sensor 2001038 in 2017\n",
      "Fetching data for sensor 2000956 in 2017\n",
      "Fetching data for sensor 2000694 in 2017\n",
      "Fetching data for sensor 2000953 in 2017\n",
      "Fetching data for sensor 2000629 in 2017\n",
      "Fetching data for sensor 2000671 in 2017\n",
      "Fetching data for sensor 2000967 in 2017\n",
      "Fetching data for sensor 2000999 in 2017\n",
      "Fetching data for sensor 2000660 in 2017\n",
      "Fetching data for sensor 2001013 in 2017\n",
      "Fetching data for sensor 2000613 in 2017\n",
      "Fetching data for sensor 2000483 in 2017\n",
      "Fetching data for sensor 2000550 in 2017\n",
      "Fetching data for sensor 2000832 in 2017\n",
      "Fetching data for sensor 2000796 in 2017\n",
      "Fetching data for sensor 2000934 in 2017\n",
      "Fetching data for sensor 2001040 in 2017\n",
      "Fetching data for sensor 2000838 in 2017\n",
      "Fetching data for sensor 2001062 in 2017\n",
      "Fetching data for sensor 2000933 in 2017\n",
      "Fetching data for sensor 2000443 in 2017\n",
      "Fetching data for sensor 2000993 in 2017\n",
      "Fetching data for sensor 2000942 in 2017\n",
      "Fetching data for sensor 2000852 in 2017\n",
      "Fetching data for sensor 2000445 in 2017\n",
      "Fetching data for sensor 2001033 in 2017\n",
      "Fetching data for sensor 2000984 in 2017\n",
      "Fetching data for sensor 2775 in 2018\n",
      "Fetching data for sensor 25551 in 2018\n",
      "Fetching data for sensor 15731 in 2018\n",
      "Fetching data for sensor 25196 in 2018\n",
      "Fetching data for sensor 24000 in 2018\n",
      "Fetching data for sensor 1654141 in 2018\n",
      "Fetching data for sensor 1654143 in 2018\n",
      "Fetching data for sensor 1654156 in 2018\n",
      "Fetching data for sensor 1654168 in 2018\n",
      "Fetching data for sensor 1654191 in 2018\n",
      "Fetching data for sensor 2000869 in 2018\n",
      "Fetching data for sensor 1654217 in 2018\n",
      "Fetching data for sensor 2000834 in 2018\n",
      "Fetching data for sensor 1654333 in 2018\n",
      "Fetching data for sensor 1654360 in 2018\n",
      "Fetching data for sensor 2000475 in 2018\n",
      "Fetching data for sensor 2000731 in 2018\n",
      "Fetching data for sensor 2000674 in 2018\n",
      "Fetching data for sensor 1654499 in 2018\n",
      "Fetching data for sensor 1654545 in 2018\n",
      "Fetching data for sensor 1654577 in 2018\n",
      "Fetching data for sensor 1654556 in 2018\n",
      "Fetching data for sensor 1654629 in 2018\n",
      "Fetching data for sensor 2000900 in 2018\n",
      "Fetching data for sensor 1999896 in 2018\n",
      "Fetching data for sensor 2001073 in 2018\n",
      "Fetching data for sensor 2001289 in 2018\n",
      "Fetching data for sensor 2001343 in 2018\n",
      "Fetching data for sensor 2088604 in 2018\n",
      "Fetching data for sensor 2088548 in 2018\n",
      "Fetching data for sensor 2088589 in 2018\n",
      "Fetching data for sensor 2000821 in 2018\n",
      "Fetching data for sensor 2000905 in 2018\n",
      "Fetching data for sensor 2000768 in 2018\n",
      "Fetching data for sensor 2000525 in 2018\n",
      "Fetching data for sensor 2000753 in 2018\n",
      "Fetching data for sensor 2000561 in 2018\n",
      "Fetching data for sensor 2000676 in 2018\n",
      "Fetching data for sensor 2001076 in 2018\n",
      "Fetching data for sensor 2000935 in 2018\n",
      "Fetching data for sensor 2000945 in 2018\n",
      "Fetching data for sensor 2000750 in 2018\n",
      "Fetching data for sensor 2001039 in 2018\n",
      "Fetching data for sensor 2000499 in 2018\n",
      "Fetching data for sensor 2000798 in 2018\n",
      "Fetching data for sensor 2000553 in 2018\n",
      "Fetching data for sensor 2000565 in 2018\n",
      "Fetching data for sensor 2000718 in 2018\n",
      "Fetching data for sensor 2000977 in 2018\n",
      "Fetching data for sensor 2000505 in 2018\n",
      "Fetching data for sensor 2000853 in 2018\n",
      "Fetching data for sensor 2000522 in 2018\n",
      "Fetching data for sensor 2000723 in 2018\n",
      "Fetching data for sensor 2000819 in 2018\n",
      "Fetching data for sensor 2000729 in 2018\n",
      "Fetching data for sensor 2001006 in 2018\n",
      "Fetching data for sensor 2000981 in 2018\n",
      "Fetching data for sensor 2000667 in 2018\n",
      "Fetching data for sensor 2000840 in 2018\n",
      "Fetching data for sensor 2000567 in 2018\n",
      "Fetching data for sensor 2000963 in 2018\n",
      "Fetching data for sensor 2000537 in 2018\n",
      "Fetching data for sensor 2000471 in 2018\n",
      "Fetching data for sensor 2001038 in 2018\n",
      "Fetching data for sensor 2000956 in 2018\n",
      "Fetching data for sensor 2000694 in 2018\n",
      "Fetching data for sensor 2000953 in 2018\n",
      "Fetching data for sensor 2000629 in 2018\n",
      "Fetching data for sensor 2000671 in 2018\n",
      "Fetching data for sensor 2000967 in 2018\n",
      "Fetching data for sensor 2000999 in 2018\n",
      "Fetching data for sensor 2000660 in 2018\n",
      "Fetching data for sensor 2001013 in 2018\n",
      "Fetching data for sensor 2000613 in 2018\n",
      "Fetching data for sensor 2000483 in 2018\n",
      "Fetching data for sensor 2000550 in 2018\n",
      "Fetching data for sensor 2000832 in 2018\n",
      "Fetching data for sensor 2000796 in 2018\n",
      "Fetching data for sensor 2000934 in 2018\n",
      "Fetching data for sensor 2001040 in 2018\n",
      "Fetching data for sensor 2000838 in 2018\n",
      "Fetching data for sensor 2001062 in 2018\n",
      "Fetching data for sensor 2000933 in 2018\n",
      "Fetching data for sensor 2000443 in 2018\n",
      "Fetching data for sensor 2000993 in 2018\n",
      "Fetching data for sensor 2000942 in 2018\n",
      "Fetching data for sensor 2000852 in 2018\n",
      "Fetching data for sensor 2000445 in 2018\n",
      "Fetching data for sensor 2001033 in 2018\n",
      "Fetching data for sensor 2000984 in 2018\n",
      "Fetching data for sensor 2775 in 2019\n",
      "Fetching data for sensor 25551 in 2019\n",
      "Fetching data for sensor 15731 in 2019\n",
      "Fetching data for sensor 25196 in 2019\n",
      "Fetching data for sensor 24000 in 2019\n",
      "Fetching data for sensor 1654141 in 2019\n",
      "Fetching data for sensor 1654143 in 2019\n",
      "Fetching data for sensor 1654156 in 2019\n",
      "Fetching data for sensor 1654168 in 2019\n",
      "Fetching data for sensor 1654191 in 2019\n",
      "Fetching data for sensor 2000869 in 2019\n",
      "Fetching data for sensor 1654217 in 2019\n",
      "Fetching data for sensor 2000834 in 2019\n",
      "Fetching data for sensor 1654333 in 2019\n",
      "Fetching data for sensor 1654360 in 2019\n",
      "Fetching data for sensor 2000475 in 2019\n",
      "Fetching data for sensor 2000731 in 2019\n",
      "Fetching data for sensor 2000674 in 2019\n",
      "Fetching data for sensor 1654499 in 2019\n",
      "Fetching data for sensor 1654545 in 2019\n",
      "Fetching data for sensor 1654577 in 2019\n",
      "Fetching data for sensor 1654556 in 2019\n",
      "Fetching data for sensor 1654629 in 2019\n",
      "Fetching data for sensor 2000900 in 2019\n",
      "Fetching data for sensor 1999896 in 2019\n",
      "Fetching data for sensor 2001073 in 2019\n",
      "Fetching data for sensor 2001289 in 2019\n",
      "Fetching data for sensor 2001343 in 2019\n",
      "Fetching data for sensor 2088604 in 2019\n",
      "Fetching data for sensor 2088548 in 2019\n",
      "Fetching data for sensor 2088589 in 2019\n",
      "Fetching data for sensor 2000821 in 2019\n",
      "Fetching data for sensor 2000905 in 2019\n",
      "Fetching data for sensor 2000768 in 2019\n",
      "Fetching data for sensor 2000525 in 2019\n",
      "Fetching data for sensor 2000753 in 2019\n",
      "Fetching data for sensor 2000561 in 2019\n",
      "Fetching data for sensor 2000676 in 2019\n",
      "Fetching data for sensor 2001076 in 2019\n",
      "Fetching data for sensor 2000935 in 2019\n",
      "Fetching data for sensor 2000945 in 2019\n",
      "Fetching data for sensor 2000750 in 2019\n",
      "Fetching data for sensor 2001039 in 2019\n",
      "Fetching data for sensor 2000499 in 2019\n",
      "Fetching data for sensor 2000798 in 2019\n",
      "Fetching data for sensor 2000553 in 2019\n",
      "Fetching data for sensor 2000565 in 2019\n",
      "Fetching data for sensor 2000718 in 2019\n",
      "Fetching data for sensor 2000977 in 2019\n",
      "Fetching data for sensor 2000505 in 2019\n",
      "Fetching data for sensor 2000853 in 2019\n",
      "Fetching data for sensor 2000522 in 2019\n",
      "Fetching data for sensor 2000723 in 2019\n",
      "Fetching data for sensor 2000819 in 2019\n",
      "Fetching data for sensor 2000729 in 2019\n",
      "Fetching data for sensor 2001006 in 2019\n",
      "Fetching data for sensor 2000981 in 2019\n",
      "Fetching data for sensor 2000667 in 2019\n",
      "Fetching data for sensor 2000840 in 2019\n",
      "Fetching data for sensor 2000567 in 2019\n",
      "Fetching data for sensor 2000963 in 2019\n",
      "Fetching data for sensor 2000537 in 2019\n",
      "Fetching data for sensor 2000471 in 2019\n",
      "Fetching data for sensor 2001038 in 2019\n",
      "Fetching data for sensor 2000956 in 2019\n",
      "Fetching data for sensor 2000694 in 2019\n",
      "Fetching data for sensor 2000953 in 2019\n",
      "Fetching data for sensor 2000629 in 2019\n",
      "Fetching data for sensor 2000671 in 2019\n",
      "Fetching data for sensor 2000967 in 2019\n",
      "Fetching data for sensor 2000999 in 2019\n",
      "Fetching data for sensor 2000660 in 2019\n",
      "Fetching data for sensor 2001013 in 2019\n",
      "Fetching data for sensor 2000613 in 2019\n",
      "Fetching data for sensor 2000483 in 2019\n",
      "Fetching data for sensor 2000550 in 2019\n",
      "Fetching data for sensor 2000832 in 2019\n",
      "Fetching data for sensor 2000796 in 2019\n",
      "Fetching data for sensor 2000934 in 2019\n",
      "Fetching data for sensor 2001040 in 2019\n",
      "Fetching data for sensor 2000838 in 2019\n",
      "Fetching data for sensor 2001062 in 2019\n",
      "Fetching data for sensor 2000933 in 2019\n",
      "Fetching data for sensor 2000443 in 2019\n",
      "Fetching data for sensor 2000993 in 2019\n",
      "Fetching data for sensor 2000942 in 2019\n",
      "Fetching data for sensor 2000852 in 2019\n",
      "Fetching data for sensor 2000445 in 2019\n",
      "Fetching data for sensor 2001033 in 2019\n",
      "Fetching data for sensor 2000984 in 2019\n",
      "Fetching data for sensor 2775 in 2020\n",
      "Fetching data for sensor 25551 in 2020\n",
      "Fetching data for sensor 15731 in 2020\n",
      "Fetching data for sensor 25196 in 2020\n",
      "Fetching data for sensor 24000 in 2020\n",
      "Fetching data for sensor 1654141 in 2020\n",
      "Fetching data for sensor 1654143 in 2020\n",
      "Fetching data for sensor 1654156 in 2020\n",
      "Fetching data for sensor 1654168 in 2020\n",
      "Fetching data for sensor 1654191 in 2020\n",
      "Fetching data for sensor 2000869 in 2020\n",
      "Fetching data for sensor 1654217 in 2020\n",
      "Fetching data for sensor 2000834 in 2020\n",
      "Fetching data for sensor 1654333 in 2020\n",
      "Fetching data for sensor 1654360 in 2020\n",
      "Fetching data for sensor 2000475 in 2020\n",
      "Fetching data for sensor 2000731 in 2020\n",
      "Fetching data for sensor 2000674 in 2020\n",
      "Fetching data for sensor 1654499 in 2020\n",
      "Fetching data for sensor 1654545 in 2020\n",
      "Fetching data for sensor 1654577 in 2020\n",
      "Fetching data for sensor 1654556 in 2020\n",
      "Fetching data for sensor 1654629 in 2020\n",
      "Fetching data for sensor 2000900 in 2020\n",
      "Fetching data for sensor 1999896 in 2020\n",
      "Fetching data for sensor 2001073 in 2020\n",
      "Fetching data for sensor 2001289 in 2020\n",
      "Fetching data for sensor 2001343 in 2020\n",
      "Fetching data for sensor 2088604 in 2020\n",
      "Fetching data for sensor 2088548 in 2020\n",
      "Fetching data for sensor 2088589 in 2020\n",
      "Fetching data for sensor 2000821 in 2020\n",
      "Fetching data for sensor 2000905 in 2020\n",
      "Fetching data for sensor 2000768 in 2020\n",
      "Fetching data for sensor 2000525 in 2020\n",
      "Fetching data for sensor 2000753 in 2020\n",
      "Fetching data for sensor 2000561 in 2020\n",
      "Fetching data for sensor 2000676 in 2020\n",
      "Fetching data for sensor 2001076 in 2020\n",
      "Fetching data for sensor 2000935 in 2020\n",
      "Fetching data for sensor 2000945 in 2020\n",
      "Fetching data for sensor 2000750 in 2020\n",
      "Fetching data for sensor 2001039 in 2020\n",
      "Fetching data for sensor 2000499 in 2020\n",
      "Fetching data for sensor 2000798 in 2020\n",
      "Fetching data for sensor 2000553 in 2020\n",
      "Fetching data for sensor 2000565 in 2020\n",
      "Fetching data for sensor 2000718 in 2020\n",
      "Fetching data for sensor 2000977 in 2020\n",
      "Fetching data for sensor 2000505 in 2020\n",
      "Fetching data for sensor 2000853 in 2020\n",
      "Fetching data for sensor 2000522 in 2020\n",
      "Fetching data for sensor 2000723 in 2020\n",
      "Fetching data for sensor 2000819 in 2020\n",
      "Fetching data for sensor 2000729 in 2020\n",
      "Fetching data for sensor 2001006 in 2020\n",
      "Fetching data for sensor 2000981 in 2020\n",
      "Fetching data for sensor 2000667 in 2020\n",
      "Fetching data for sensor 2000840 in 2020\n",
      "Fetching data for sensor 2000567 in 2020\n",
      "Fetching data for sensor 2000963 in 2020\n",
      "Fetching data for sensor 2000537 in 2020\n",
      "Fetching data for sensor 2000471 in 2020\n",
      "Fetching data for sensor 2001038 in 2020\n",
      "Fetching data for sensor 2000956 in 2020\n",
      "Fetching data for sensor 2000694 in 2020\n",
      "Fetching data for sensor 2000953 in 2020\n",
      "Fetching data for sensor 2000629 in 2020\n",
      "Fetching data for sensor 2000671 in 2020\n",
      "Fetching data for sensor 2000967 in 2020\n",
      "Fetching data for sensor 2000999 in 2020\n",
      "Fetching data for sensor 2000660 in 2020\n",
      "Fetching data for sensor 2001013 in 2020\n",
      "Fetching data for sensor 2000613 in 2020\n",
      "Fetching data for sensor 2000483 in 2020\n",
      "Fetching data for sensor 2000550 in 2020\n",
      "Fetching data for sensor 2000832 in 2020\n",
      "Fetching data for sensor 2000796 in 2020\n",
      "Fetching data for sensor 2000934 in 2020\n",
      "Fetching data for sensor 2001040 in 2020\n",
      "Fetching data for sensor 2000838 in 2020\n",
      "Fetching data for sensor 2001062 in 2020\n",
      "Fetching data for sensor 2000933 in 2020\n",
      "Fetching data for sensor 2000443 in 2020\n",
      "Fetching data for sensor 2000993 in 2020\n",
      "Fetching data for sensor 2000942 in 2020\n",
      "Fetching data for sensor 2000852 in 2020\n",
      "Fetching data for sensor 2000445 in 2020\n",
      "Fetching data for sensor 2001033 in 2020\n",
      "Fetching data for sensor 2000984 in 2020\n",
      "Fetching data for sensor 2775 in 2021\n",
      "Fetching data for sensor 25551 in 2021\n",
      "Fetching data for sensor 15731 in 2021\n",
      "Fetching data for sensor 25196 in 2021\n",
      "Fetching data for sensor 24000 in 2021\n",
      "Fetching data for sensor 1654141 in 2021\n",
      "Fetching data for sensor 1654143 in 2021\n",
      "Fetching data for sensor 1654156 in 2021\n",
      "Fetching data for sensor 1654168 in 2021\n",
      "Fetching data for sensor 1654191 in 2021\n",
      "Fetching data for sensor 2000869 in 2021\n",
      "Fetching data for sensor 1654217 in 2021\n",
      "Fetching data for sensor 2000834 in 2021\n",
      "Fetching data for sensor 1654333 in 2021\n",
      "Fetching data for sensor 1654360 in 2021\n",
      "Fetching data for sensor 2000475 in 2021\n",
      "Fetching data for sensor 2000731 in 2021\n",
      "Fetching data for sensor 2000674 in 2021\n",
      "Fetching data for sensor 1654499 in 2021\n",
      "Fetching data for sensor 1654545 in 2021\n",
      "Fetching data for sensor 1654577 in 2021\n",
      "Fetching data for sensor 1654556 in 2021\n",
      "Fetching data for sensor 1654629 in 2021\n",
      "Fetching data for sensor 2000900 in 2021\n",
      "Fetching data for sensor 1999896 in 2021\n",
      "Fetching data for sensor 2001073 in 2021\n",
      "Fetching data for sensor 2001289 in 2021\n",
      "Fetching data for sensor 2001343 in 2021\n",
      "Fetching data for sensor 2088604 in 2021\n",
      "Fetching data for sensor 2088548 in 2021\n",
      "Fetching data for sensor 2088589 in 2021\n",
      "Fetching data for sensor 2000821 in 2021\n",
      "Fetching data for sensor 2000905 in 2021\n",
      "Fetching data for sensor 2000768 in 2021\n",
      "Fetching data for sensor 2000525 in 2021\n",
      "Fetching data for sensor 2000753 in 2021\n",
      "Fetching data for sensor 2000561 in 2021\n",
      "Fetching data for sensor 2000676 in 2021\n",
      "Fetching data for sensor 2001076 in 2021\n",
      "Fetching data for sensor 2000935 in 2021\n",
      "Fetching data for sensor 2000945 in 2021\n",
      "Fetching data for sensor 2000750 in 2021\n",
      "Fetching data for sensor 2001039 in 2021\n",
      "Fetching data for sensor 2000499 in 2021\n",
      "Fetching data for sensor 2000798 in 2021\n",
      "Fetching data for sensor 2000553 in 2021\n",
      "Fetching data for sensor 2000565 in 2021\n",
      "Fetching data for sensor 2000718 in 2021\n",
      "Fetching data for sensor 2000977 in 2021\n",
      "Fetching data for sensor 2000505 in 2021\n",
      "Fetching data for sensor 2000853 in 2021\n",
      "Fetching data for sensor 2000522 in 2021\n",
      "Fetching data for sensor 2000723 in 2021\n",
      "Fetching data for sensor 2000819 in 2021\n",
      "Fetching data for sensor 2000729 in 2021\n",
      "Fetching data for sensor 2001006 in 2021\n",
      "Fetching data for sensor 2000981 in 2021\n",
      "Fetching data for sensor 2000667 in 2021\n",
      "Fetching data for sensor 2000840 in 2021\n",
      "Fetching data for sensor 2000567 in 2021\n",
      "Fetching data for sensor 2000963 in 2021\n",
      "Fetching data for sensor 2000537 in 2021\n",
      "Fetching data for sensor 2000471 in 2021\n",
      "Fetching data for sensor 2001038 in 2021\n",
      "Fetching data for sensor 2000956 in 2021\n",
      "Fetching data for sensor 2000694 in 2021\n",
      "Fetching data for sensor 2000953 in 2021\n",
      "Fetching data for sensor 2000629 in 2021\n",
      "Fetching data for sensor 2000671 in 2021\n",
      "Fetching data for sensor 2000967 in 2021\n",
      "Fetching data for sensor 2000999 in 2021\n",
      "Fetching data for sensor 2000660 in 2021\n",
      "Fetching data for sensor 2001013 in 2021\n",
      "Fetching data for sensor 2000613 in 2021\n",
      "Fetching data for sensor 2000483 in 2021\n",
      "Fetching data for sensor 2000550 in 2021\n",
      "Fetching data for sensor 2000832 in 2021\n",
      "Fetching data for sensor 2000796 in 2021\n",
      "Fetching data for sensor 2000934 in 2021\n",
      "Fetching data for sensor 2001040 in 2021\n",
      "Fetching data for sensor 2000838 in 2021\n",
      "Fetching data for sensor 2001062 in 2021\n",
      "Fetching data for sensor 2000933 in 2021\n",
      "Fetching data for sensor 2000443 in 2021\n",
      "Fetching data for sensor 2000993 in 2021\n",
      "Fetching data for sensor 2000942 in 2021\n",
      "Fetching data for sensor 2000852 in 2021\n",
      "Fetching data for sensor 2000445 in 2021\n",
      "Fetching data for sensor 2001033 in 2021\n",
      "Fetching data for sensor 2000984 in 2021\n",
      "Fetching data for sensor 2775 in 2022\n",
      "Fetching data for sensor 25551 in 2022\n",
      "Fetching data for sensor 15731 in 2022\n",
      "Fetching data for sensor 25196 in 2022\n",
      "Fetching data for sensor 24000 in 2022\n",
      "Fetching data for sensor 1654141 in 2022\n",
      "Fetching data for sensor 1654143 in 2022\n",
      "Fetching data for sensor 1654156 in 2022\n",
      "Fetching data for sensor 1654168 in 2022\n",
      "Fetching data for sensor 1654191 in 2022\n",
      "Fetching data for sensor 2000869 in 2022\n",
      "Fetching data for sensor 1654217 in 2022\n",
      "Fetching data for sensor 2000834 in 2022\n",
      "Fetching data for sensor 1654333 in 2022\n",
      "Fetching data for sensor 1654360 in 2022\n",
      "Fetching data for sensor 2000475 in 2022\n",
      "Fetching data for sensor 2000731 in 2022\n",
      "Fetching data for sensor 2000674 in 2022\n",
      "Fetching data for sensor 1654499 in 2022\n",
      "Fetching data for sensor 1654545 in 2022\n",
      "Fetching data for sensor 1654577 in 2022\n",
      "Fetching data for sensor 1654556 in 2022\n",
      "Fetching data for sensor 1654629 in 2022\n",
      "Fetching data for sensor 2000900 in 2022\n",
      "Fetching data for sensor 1999896 in 2022\n",
      "Fetching data for sensor 2001073 in 2022\n",
      "Fetching data for sensor 2001289 in 2022\n",
      "Fetching data for sensor 2001343 in 2022\n",
      "Fetching data for sensor 2088604 in 2022\n",
      "Fetching data for sensor 2088548 in 2022\n",
      "Fetching data for sensor 2088589 in 2022\n",
      "Fetching data for sensor 2000821 in 2022\n",
      "Fetching data for sensor 2000905 in 2022\n",
      "Fetching data for sensor 2000768 in 2022\n",
      "Fetching data for sensor 2000525 in 2022\n",
      "Fetching data for sensor 2000753 in 2022\n",
      "Fetching data for sensor 2000561 in 2022\n",
      "Fetching data for sensor 2000676 in 2022\n",
      "Fetching data for sensor 2001076 in 2022\n",
      "Fetching data for sensor 2000935 in 2022\n",
      "Fetching data for sensor 2000945 in 2022\n",
      "Fetching data for sensor 2000750 in 2022\n",
      "Fetching data for sensor 2001039 in 2022\n",
      "Fetching data for sensor 2000499 in 2022\n",
      "Fetching data for sensor 2000798 in 2022\n",
      "Fetching data for sensor 2000553 in 2022\n",
      "Fetching data for sensor 2000565 in 2022\n",
      "Fetching data for sensor 2000718 in 2022\n",
      "Fetching data for sensor 2000977 in 2022\n",
      "Fetching data for sensor 2000505 in 2022\n",
      "Fetching data for sensor 2000853 in 2022\n",
      "Fetching data for sensor 2000522 in 2022\n",
      "Fetching data for sensor 2000723 in 2022\n",
      "Fetching data for sensor 2000819 in 2022\n",
      "Fetching data for sensor 2000729 in 2022\n",
      "Fetching data for sensor 2001006 in 2022\n",
      "Fetching data for sensor 2000981 in 2022\n",
      "Fetching data for sensor 2000667 in 2022\n",
      "Fetching data for sensor 2000840 in 2022\n",
      "Fetching data for sensor 2000567 in 2022\n",
      "Fetching data for sensor 2000963 in 2022\n",
      "Fetching data for sensor 2000537 in 2022\n",
      "Fetching data for sensor 2000471 in 2022\n",
      "Fetching data for sensor 2001038 in 2022\n",
      "Fetching data for sensor 2000956 in 2022\n",
      "Fetching data for sensor 2000694 in 2022\n",
      "Fetching data for sensor 2000953 in 2022\n",
      "Fetching data for sensor 2000629 in 2022\n",
      "Fetching data for sensor 2000671 in 2022\n",
      "Fetching data for sensor 2000967 in 2022\n",
      "Fetching data for sensor 2000999 in 2022\n",
      "Fetching data for sensor 2000660 in 2022\n",
      "Fetching data for sensor 2001013 in 2022\n",
      "Fetching data for sensor 2000613 in 2022\n",
      "Fetching data for sensor 2000483 in 2022\n",
      "Fetching data for sensor 2000550 in 2022\n",
      "Fetching data for sensor 2000832 in 2022\n",
      "Fetching data for sensor 2000796 in 2022\n",
      "Fetching data for sensor 2000934 in 2022\n",
      "Fetching data for sensor 2001040 in 2022\n",
      "Fetching data for sensor 2000838 in 2022\n",
      "Fetching data for sensor 2001062 in 2022\n",
      "Fetching data for sensor 2000933 in 2022\n",
      "Fetching data for sensor 2000443 in 2022\n",
      "Fetching data for sensor 2000993 in 2022\n",
      "Fetching data for sensor 2000942 in 2022\n",
      "Fetching data for sensor 2000852 in 2022\n",
      "Fetching data for sensor 2000445 in 2022\n",
      "Fetching data for sensor 2001033 in 2022\n",
      "Fetching data for sensor 2000984 in 2022\n",
      "Fetching data for sensor 2775 in 2023\n",
      "Fetching data for sensor 25551 in 2023\n",
      "Fetching data for sensor 15731 in 2023\n",
      "Fetching data for sensor 25196 in 2023\n",
      "Fetching data for sensor 24000 in 2023\n",
      "Fetching data for sensor 1654141 in 2023\n",
      "Fetching data for sensor 1654143 in 2023\n",
      "Fetching data for sensor 1654156 in 2023\n",
      "Fetching data for sensor 1654168 in 2023\n",
      "Fetching data for sensor 1654191 in 2023\n",
      "Fetching data for sensor 2000869 in 2023\n",
      "Fetching data for sensor 1654217 in 2023\n",
      "Fetching data for sensor 2000834 in 2023\n",
      "Fetching data for sensor 1654333 in 2023\n",
      "Fetching data for sensor 1654360 in 2023\n",
      "Fetching data for sensor 2000475 in 2023\n",
      "Fetching data for sensor 2000731 in 2023\n",
      "Fetching data for sensor 2000674 in 2023\n",
      "Fetching data for sensor 1654499 in 2023\n",
      "Fetching data for sensor 1654545 in 2023\n",
      "Fetching data for sensor 1654577 in 2023\n",
      "Fetching data for sensor 1654556 in 2023\n",
      "Fetching data for sensor 1654629 in 2023\n",
      "Fetching data for sensor 2000900 in 2023\n",
      "Fetching data for sensor 1999896 in 2023\n",
      "Fetching data for sensor 2001073 in 2023\n",
      "Fetching data for sensor 2001289 in 2023\n",
      "Fetching data for sensor 2001343 in 2023\n",
      "Fetching data for sensor 2088604 in 2023\n",
      "Fetching data for sensor 2088548 in 2023\n",
      "Fetching data for sensor 2088589 in 2023\n",
      "Fetching data for sensor 2000821 in 2023\n",
      "Fetching data for sensor 2000905 in 2023\n",
      "Fetching data for sensor 2000768 in 2023\n",
      "Fetching data for sensor 2000525 in 2023\n",
      "Fetching data for sensor 2000753 in 2023\n",
      "Fetching data for sensor 2000561 in 2023\n",
      "Fetching data for sensor 2000676 in 2023\n",
      "Fetching data for sensor 2001076 in 2023\n",
      "Fetching data for sensor 2000935 in 2023\n",
      "Fetching data for sensor 2000945 in 2023\n",
      "Fetching data for sensor 2000750 in 2023\n",
      "Fetching data for sensor 2001039 in 2023\n",
      "Fetching data for sensor 2000499 in 2023\n",
      "Fetching data for sensor 2000798 in 2023\n",
      "Fetching data for sensor 2000553 in 2023\n",
      "Fetching data for sensor 2000565 in 2023\n",
      "Fetching data for sensor 2000718 in 2023\n",
      "Fetching data for sensor 2000977 in 2023\n",
      "Fetching data for sensor 2000505 in 2023\n",
      "Fetching data for sensor 2000853 in 2023\n",
      "Fetching data for sensor 2000522 in 2023\n",
      "Fetching data for sensor 2000723 in 2023\n",
      "Fetching data for sensor 2000819 in 2023\n",
      "Fetching data for sensor 2000729 in 2023\n",
      "Fetching data for sensor 2001006 in 2023\n",
      "Fetching data for sensor 2000981 in 2023\n",
      "Fetching data for sensor 2000667 in 2023\n",
      "Fetching data for sensor 2000840 in 2023\n",
      "Fetching data for sensor 2000567 in 2023\n",
      "Fetching data for sensor 2000963 in 2023\n",
      "Fetching data for sensor 2000537 in 2023\n",
      "Fetching data for sensor 2000471 in 2023\n",
      "Fetching data for sensor 2001038 in 2023\n",
      "Fetching data for sensor 2000956 in 2023\n",
      "Fetching data for sensor 2000694 in 2023\n",
      "Fetching data for sensor 2000953 in 2023\n",
      "Fetching data for sensor 2000629 in 2023\n",
      "Fetching data for sensor 2000671 in 2023\n",
      "Fetching data for sensor 2000967 in 2023\n",
      "Fetching data for sensor 2000999 in 2023\n",
      "Fetching data for sensor 2000660 in 2023\n",
      "Fetching data for sensor 2001013 in 2023\n",
      "Fetching data for sensor 2000613 in 2023\n",
      "Fetching data for sensor 2000483 in 2023\n",
      "Fetching data for sensor 2000550 in 2023\n",
      "Fetching data for sensor 2000832 in 2023\n",
      "Fetching data for sensor 2000796 in 2023\n",
      "Fetching data for sensor 2000934 in 2023\n",
      "Fetching data for sensor 2001040 in 2023\n",
      "Fetching data for sensor 2000838 in 2023\n",
      "Fetching data for sensor 2001062 in 2023\n",
      "Fetching data for sensor 2000933 in 2023\n",
      "Fetching data for sensor 2000443 in 2023\n",
      "Fetching data for sensor 2000993 in 2023\n",
      "Fetching data for sensor 2000942 in 2023\n",
      "Fetching data for sensor 2000852 in 2023\n",
      "Fetching data for sensor 2000445 in 2023\n",
      "Fetching data for sensor 2001033 in 2023\n",
      "Fetching data for sensor 2000984 in 2023\n",
      "Fetching data for sensor 2775 in 2024\n",
      "Fetching data for sensor 25551 in 2024\n",
      "Fetching data for sensor 15731 in 2024\n",
      "Fetching data for sensor 25196 in 2024\n",
      "Fetching data for sensor 24000 in 2024\n",
      "Fetching data for sensor 1654141 in 2024\n",
      "Fetching data for sensor 1654143 in 2024\n",
      "Fetching data for sensor 1654156 in 2024\n",
      "Fetching data for sensor 1654168 in 2024\n",
      "Fetching data for sensor 1654191 in 2024\n",
      "Fetching data for sensor 2000869 in 2024\n",
      "Fetching data for sensor 1654217 in 2024\n",
      "Fetching data for sensor 2000834 in 2024\n",
      "Fetching data for sensor 1654333 in 2024\n",
      "Fetching data for sensor 1654360 in 2024\n",
      "Fetching data for sensor 2000475 in 2024\n",
      "Fetching data for sensor 2000731 in 2024\n",
      "Fetching data for sensor 2000674 in 2024\n",
      "Fetching data for sensor 1654499 in 2024\n",
      "Fetching data for sensor 1654545 in 2024\n",
      "Fetching data for sensor 1654577 in 2024\n",
      "Fetching data for sensor 1654556 in 2024\n",
      "Fetching data for sensor 1654629 in 2024\n",
      "Fetching data for sensor 2000900 in 2024\n",
      "Fetching data for sensor 1999896 in 2024\n",
      "Fetching data for sensor 2001073 in 2024\n",
      "Fetching data for sensor 2001289 in 2024\n",
      "Fetching data for sensor 2001343 in 2024\n",
      "Fetching data for sensor 2088604 in 2024\n",
      "Fetching data for sensor 2088548 in 2024\n",
      "Fetching data for sensor 2088589 in 2024\n",
      "Fetching data for sensor 2000821 in 2024\n",
      "Fetching data for sensor 2000905 in 2024\n",
      "Fetching data for sensor 2000768 in 2024\n",
      "Fetching data for sensor 2000525 in 2024\n",
      "Fetching data for sensor 2000753 in 2024\n",
      "Fetching data for sensor 2000561 in 2024\n",
      "Fetching data for sensor 2000676 in 2024\n",
      "Fetching data for sensor 2001076 in 2024\n",
      "Fetching data for sensor 2000935 in 2024\n",
      "Fetching data for sensor 2000945 in 2024\n",
      "Fetching data for sensor 2000750 in 2024\n",
      "Fetching data for sensor 2001039 in 2024\n",
      "Fetching data for sensor 2000499 in 2024\n",
      "Fetching data for sensor 2000798 in 2024\n",
      "Fetching data for sensor 2000553 in 2024\n",
      "Fetching data for sensor 2000565 in 2024\n",
      "Fetching data for sensor 2000718 in 2024\n",
      "Fetching data for sensor 2000977 in 2024\n",
      "Fetching data for sensor 2000505 in 2024\n",
      "Fetching data for sensor 2000853 in 2024\n",
      "Fetching data for sensor 2000522 in 2024\n",
      "Fetching data for sensor 2000723 in 2024\n",
      "Fetching data for sensor 2000819 in 2024\n",
      "Fetching data for sensor 2000729 in 2024\n",
      "Fetching data for sensor 2001006 in 2024\n",
      "Fetching data for sensor 2000981 in 2024\n",
      "Fetching data for sensor 2000667 in 2024\n",
      "Fetching data for sensor 2000840 in 2024\n",
      "Fetching data for sensor 2000567 in 2024\n",
      "Fetching data for sensor 2000963 in 2024\n",
      "Fetching data for sensor 2000537 in 2024\n",
      "Fetching data for sensor 2000471 in 2024\n",
      "Fetching data for sensor 2001038 in 2024\n",
      "Fetching data for sensor 2000956 in 2024\n",
      "Fetching data for sensor 2000694 in 2024\n",
      "Fetching data for sensor 2000953 in 2024\n",
      "Fetching data for sensor 2000629 in 2024\n",
      "Fetching data for sensor 2000671 in 2024\n",
      "Fetching data for sensor 2000967 in 2024\n",
      "Fetching data for sensor 2000999 in 2024\n",
      "Fetching data for sensor 2000660 in 2024\n",
      "Fetching data for sensor 2001013 in 2024\n",
      "Fetching data for sensor 2000613 in 2024\n",
      "Fetching data for sensor 2000483 in 2024\n",
      "Fetching data for sensor 2000550 in 2024\n",
      "Fetching data for sensor 2000832 in 2024\n",
      "Fetching data for sensor 2000796 in 2024\n",
      "Fetching data for sensor 2000934 in 2024\n",
      "Fetching data for sensor 2001040 in 2024\n",
      "Fetching data for sensor 2000838 in 2024\n",
      "Fetching data for sensor 2001062 in 2024\n",
      "Fetching data for sensor 2000933 in 2024\n",
      "Fetching data for sensor 2000443 in 2024\n",
      "Fetching data for sensor 2000993 in 2024\n",
      "Fetching data for sensor 2000942 in 2024\n",
      "Fetching data for sensor 2000852 in 2024\n",
      "Fetching data for sensor 2000445 in 2024\n",
      "Fetching data for sensor 2001033 in 2024\n",
      "Fetching data for sensor 2000984 in 2024\n",
      "             day        avg  isUnhealthy\n",
      "0     2016-03-06   8.000000            0\n",
      "1     2016-03-07   4.500000            0\n",
      "2     2016-03-10  15.000000            1\n",
      "3     2016-03-11   9.080000            0\n",
      "4     2016-03-12   7.860000            0\n",
      "...          ...        ...          ...\n",
      "3051  2024-12-27  15.662807            1\n",
      "3052  2024-12-28  22.475439            1\n",
      "3053  2024-12-29  24.024561            1\n",
      "3054  2024-12-30  25.638596            1\n",
      "3055  2024-12-31  30.856140            1\n",
      "\n",
      "[3056 rows x 3 columns]\n",
      "aq_df.shape = (3056, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>avg</th>\n",
       "      <th>isUnhealthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-07</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-11</td>\n",
       "      <td>9.080000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>15.662807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>22.475439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>24.024561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>25.638596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>30.856140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3056 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             day        avg  isUnhealthy\n",
       "0     2016-03-06   8.000000            0\n",
       "1     2016-03-07   4.500000            0\n",
       "2     2016-03-10  15.000000            1\n",
       "3     2016-03-11   9.080000            0\n",
       "4     2016-03-12   7.860000            0\n",
       "...          ...        ...          ...\n",
       "3051  2024-12-27  15.662807            1\n",
       "3052  2024-12-28  22.475439            1\n",
       "3053  2024-12-29  24.024561            1\n",
       "3054  2024-12-30  25.638596            1\n",
       "3055  2024-12-31  30.856140            1\n",
       "\n",
       "[3056 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 63] File name too long: 'dataOpenAQ_los-angeles_pm25_2016-2024_2775-25551-15731-25196-24000-1654141-1654143-1654156-1654168-1654191-2000869-1654217-2000834-1654333-1654360-2000475-2000731-2000674-1654499-1654545-1654577-1654556-1654629-2000900-1999896-2001073-2001289-2001343-2088604-2088548-2088589-2000821-2000905-2000768-2000525-2000753-2000561-2000676-2001076-2000935-2000945-2000750-2001039-2000499-2000798-2000553-2000565-2000718-2000977-2000505-2000853-2000522-2000723-2000819-2000729-2001006-2000981-2000667-2000840-2000567-2000963-2000537-2000471-2001038-2000956-2000694-2000953-2000629-2000671-2000967-2000999-2000660-2001013-2000613-2000483-2000550-2000832-2000796-2000934-2001040-2000838-2001062-2000933-2000443-2000993-2000942-2000852-2000445-2001033-2000984.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33maq_df.shape =\u001b[39m\u001b[33m'\u001b[39m, aq_df.shape)\n\u001b[32m      9\u001b[39m display(aq_df)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43maq_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAQbyWeather\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetFilenameOpenAQ\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/aws/aqi/.venv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/aws/aqi/.venv/lib/python3.12/site-packages/pandas/core/generic.py:3967\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3956\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3958\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m     frame=df,\n\u001b[32m   3960\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m     decimal=decimal,\n\u001b[32m   3965\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3972\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/aws/aqi/.venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/aws/aqi/.venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/aws/aqi/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mOSError\u001b[39m: [Errno 63] File name too long: 'dataOpenAQ_los-angeles_pm25_2016-2024_2775-25551-15731-25196-24000-1654141-1654143-1654156-1654168-1654191-2000869-1654217-2000834-1654333-1654360-2000475-2000731-2000674-1654499-1654545-1654577-1654556-1654629-2000900-1999896-2001073-2001289-2001343-2088604-2088548-2088589-2000821-2000905-2000768-2000525-2000753-2000561-2000676-2001076-2000935-2000945-2000750-2001039-2000499-2000798-2000553-2000565-2000718-2000977-2000505-2000853-2000522-2000723-2000819-2000729-2001006-2000981-2000667-2000840-2000567-2000963-2000537-2000471-2001038-2000956-2000694-2000953-2000629-2000671-2000967-2000999-2000660-2001013-2000613-2000483-2000550-2000832-2000796-2000934-2001040-2000838-2001062-2000933-2000443-2000993-2000942-2000852-2000445-2001033-2000984.csv'"
     ]
    }
   ],
   "source": [
    "# GET OPENAQ AIR QUALITY DAILY AVERAGES DATA...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "aq_df = AQbyWeather.getOpenAqDataFrame() # Gets nearby Location IDs THEN gets associated daily averages.\n",
    "print(aq_df)\n",
    "\n",
    "if len(aq_df) > 0:\n",
    "    # Output DataFrame properties...\n",
    "    print('aq_df.shape =', aq_df.shape)\n",
    "    display(aq_df)\n",
    "    aq_df.to_csv(AQbyWeather.getFilenameOpenAQ(), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the NOAA GSOD weather data with our OpenAQ data by DATE...\n",
    "# Perform another column drop to remove columns we don't want as features/inputs.\n",
    "# This column removal will NOT be necessary once we can use Autogluon ignore_columns param (TBD).\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "# Debug merge operation\n",
    "print(\"NOAA GSOD data shape:\", noaagsod_df.shape)\n",
    "print(\"\\nNOAA GSOD sample dates:\")\n",
    "print(noaagsod_df['DATE'].head())\n",
    "print(noaagsod_df.columns.tolist())   # list of all column names\n",
    "\n",
    "print(\"\\nOpenAQ data shape:\", aq_df.shape) \n",
    "print(\"\\nOpenAQ sample dates:\")\n",
    "print(aq_df['day'].head())\n",
    "\n",
    "# Check for date format consistency\n",
    "print(\"\\nNOAA date type:\", noaagsod_df['DATE'].dtype)\n",
    "print(\"OpenAQ date type:\", aq_df['day'].dtype)\n",
    "\n",
    "# Attempt merge with debug info\n",
    "merged_df = AQbyWeather.getMergedDataFrame(noaagsod_df, aq_df)\n",
    "print(\"\\nMerged data shape:\", merged_df.shape)\n",
    "if(len(merged_df) > 0):\n",
    "    # Output DataFrame properties...\n",
    "    print('merged_df.shape =', merged_df.shape)\n",
    "    display(merged_df)\n",
    "    merged_df.groupby([AQbyWeather.mlTargetLabel]).size().plot(kind=\"bar\")\n",
    "    merged_df.to_csv(AQbyWeather.getFilenameOther(\"dataMERGED\"), index=False)\n",
    "\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.features.generators import PipelineFeatureGenerator, CategoryFeatureGenerator, IdentityFeatureGenerator\n",
    "from autogluon.common.features.types import R_INT, R_FLOAT\n",
    "from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
    "\n",
    "columns_to_drop=['MIN_ATTRIBUTES', 'MAX_ATTRIBUTES']\n",
    "merged_df = merged_df.drop(columns=[col for col in columns_to_drop if col in merged_df.columns])\n",
    "\n",
    "merged_df = merged_df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "auto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\n",
    "merged_df = auto_ml_pipeline_feature_generator.fit_transform(X=merged_df)\n",
    "\n",
    "print(\"\\nColumn dtypes:\")\n",
    "print(merged_df.dtypes)\n",
    "\n",
    "# mypipeline = PipelineFeatureGenerator(\n",
    "#     generators = [[        \n",
    "#         CategoryFeatureGenerator(maximum_num_cat=10),  # Overridden from default.\n",
    "#         IdentityFeatureGenerator(infer_features_in_args=dict(valid_raw_types=[R_INT, R_FLOAT])),\n",
    "#     ]]\n",
    "# )\n",
    "# mypipeline.fit_transform(X=merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations in our merged dataframe...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "correlations = merged_df.corr()\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0, len(merged_df.columns), 1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(merged_df.columns)\n",
    "ax.set_yticklabels(merged_df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the NOAA GSOD weather data with our OpenAQ data by DATE...\n",
    "# Perform another column drop to remove columns we don't want as features/inputs.\n",
    "# This column removal will NOT be necessary once we can use Autogluon ignore_columns param (TBD).\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "# Debug merge operation\n",
    "print(\"NOAA GSOD data shape:\", noaagsod_df.shape)\n",
    "print(\"\\nNOAA GSOD sample dates:\")\n",
    "print(noaagsod_df['DATE'].head())\n",
    "\n",
    "print(\"\\nOpenAQ data shape:\", aq_df.shape) \n",
    "print(\"\\nOpenAQ sample dates:\")\n",
    "print(aq_df['day'].head())\n",
    "\n",
    "# Check for date format consistency\n",
    "print(\"\\nNOAA date type:\", noaagsod_df['DATE'].dtype)\n",
    "print(\"OpenAQ date type:\", aq_df['day'].dtype)\n",
    "\n",
    "# Attempt merge with debug info\n",
    "merged_df = AQbyWeather.getMergedDataFrame(noaagsod_df, aq_df)\n",
    "print(\"\\nMerged data shape:\", merged_df.shape)\n",
    "if(len(merged_df) > 0):\n",
    "    merged_df.groupby([AQbyWeather.mlTargetLabel]).size().plot(kind=\"bar\")\n",
    "    merged_df.to_csv(AQbyWeather.getFilenameOther(\"dataMERGED\"), index=False)\n",
    "\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional import statements for autogluon+sklearn and split out train_df + validate_df data...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "train_df, validate_df = train_test_split(merged_df, test_size=0.25, random_state=1)\n",
    "print('Number of training samples:', len(train_df))\n",
    "print('Number of validation samples:', len(validate_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test_df data and remove the target label column...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "test_df=validate_df.drop([AQbyWeather.mlTargetLabel], axis=1)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.common import space\n",
    "\n",
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 50,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': space.Real(1e-4, 1e-2, default=1e-3, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'dropout_prob': space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "num_trials = 10  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "time_limit = 60 * 60\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}  # Refer to TabularPredictor.fit docstring for all valid values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use AutoGluon TabularPredictor to fit a model for our training data...\n",
    "display(AQbyWeather.selectedScenario.getSummary()) #Using display for consistent/sequential output order.\n",
    "predictor = TabularPredictor(label=AQbyWeather.mlTargetLabel, \n",
    "                             eval_metric=AQbyWeather.mlEvalMetric, \n",
    "                             path=AQbyWeather.selectedScenario.getModelPath())\n",
    "predictor.fit(train_data=train_df, auto_stack=True, time_limit=time_limit, hyperparameters=hyperparameters,\n",
    "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs, verbosity=3, presets='best_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframes for feature importance + model leaderboard AND get+display model evaluation...\n",
    "display(AQbyWeather.selectedScenario.getSummary()) #Using display for consistent/sequential output order.\n",
    "featureimp_df   = predictor.feature_importance(validate_df)\n",
    "leaderboard_df  = predictor.leaderboard(validate_df, silent=True)\n",
    "modelEvaluation = predictor.evaluate(validate_df, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Autogluon Individual Model Leaderboard...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "display(leaderboard_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View and Plot Feature Importance... (this various from Scenario to Scenario)\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "display(featureimp_df)\n",
    "featureimp_df.drop(columns=[\"n\"]).plot(kind=\"bar\", figsize=(12, 4), xlabel=\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load + Use Our Model (this line is unnecessary, but shows how to load a built model)...\n",
    "predictor = TabularPredictor.load(AQbyWeather.selectedScenario.getModelPath())\n",
    "\n",
    "# Make Predictions, which are saved to an array: y_pred\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "y_pred = predictor.predict(test_df)\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true label values as an array: y_true\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "y_true = validate_df[AQbyWeather.mlTargetLabel]\n",
    "display(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Confusion Matrix (CM), Get Additional CM Data, View CM...\n",
    "# Learn More: https://towardsdatascience.com/confusion-matrix-what-is-it-e859e1bbecdc\n",
    "#             https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print Confusion Matrix data...\n",
    "cmData = AQbyWeather.getConfusionMatrixData(cm)\n",
    "print(cmData.TN_Output)\n",
    "print(cmData.TP_Output)\n",
    "print(cmData.FN_Output)\n",
    "print(cmData.FP_Output)\n",
    "\n",
    "# Plot Confusion Matrix...\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "cmd.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save final results...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "resultsFile = AQbyWeather.getFilenameOther(\"dataRESULTS\")\n",
    "results_df = pd.DataFrame()\n",
    "results_df['PREDICTION'] = pd.DataFrame(y_pred)\n",
    "results_df = pd.concat([validate_df, results_df], axis=1)\n",
    "results_df.to_csv(resultsFile, index=False)\n",
    "print(f\"Results saved to {resultsFile}. DONE.\")\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
