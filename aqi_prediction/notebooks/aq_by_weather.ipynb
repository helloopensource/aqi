{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFER FROM AWS DEMO REPO!!!\n",
    "# Set up your environment according to the repo's environment.yml file or run the following...\n",
    "# Comment these out, once installed or otherwise not needed.\n",
    "# This creates an empty pip_requirements.txt file used to suppress 'already satisfied' output.\n",
    "import os\n",
    "with open('pip_requirements.txt', mode='a'): pass\n",
    "%pip install boto3        -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install pandas       -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install numpy        -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install requests     -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install ipywidgets   -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install scikit-learn -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install autogluon    -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install matplotlib   -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install nbconvert    -r pip_requirements.txt | grep -v 'already satisfied'\n",
    "%pip install python-dotenv    -r pip_requirements.txt | grep -v 'already satisfied'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements for packages used...\n",
    "import os, glob, shutil, sys, requests, json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from types import SimpleNamespace\n",
    "from IPython.display import clear_output\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "# Since __file__ is not defined in notebooks, we need to get the current notebook path\n",
    "import inspect\n",
    "notebook_path = inspect.getfile(inspect.currentframe())\n",
    "\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path(notebook_path).resolve().parent.parent))\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access them\n",
    "api_key = os.getenv('OPENAQ_API_KEY')\n",
    "\n",
    "# The following is required for matplotlib plots to display in some envs...\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AQParam => Used to define attributes for the (6) main OpenAQ parameters.\n",
    "class AQParam:\n",
    "    def __init__(self, id, name, unit, unhealthyThresholdDefault, desc):\n",
    "        self.id                        = id\n",
    "        self.name                      = name\n",
    "        self.unit                      = unit\n",
    "        self.unhealthyThresholdDefault = unhealthyThresholdDefault\n",
    "        self.desc                      = desc\n",
    "    \n",
    "    def isValid(self):\n",
    "        if(self is not None and self.id > 0 and self.unhealthyThresholdDefault > 0.0 and \n",
    "           len(self.name) > 0 and len(self.unit) > 0 and len(self.desc) > 0):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    def toJSON(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=2)\n",
    "\n",
    "# class AQScenario => Defines an ML scenario including a Location w/ NOAA Weather Station ID \n",
    "#                     and the target OpenAQ Param.\n",
    "# Note: OpenAQ data mostly begins sometime in 2016, so using that as a default yearStart value.\n",
    "class AQScenario:\n",
    "    def __init__(self, location=None, noaaStationID=None, aqParamTarget=None, unhealthyThreshold=None, \n",
    "                 yearStart=2016, yearEnd=2024, aqRadiusMiles=10, featureColumnsToDrop=None):\n",
    "        self.location           = location\n",
    "        self.name               = location + \"_\" + aqParamTarget.name\n",
    "        self.noaaStationID      = noaaStationID\n",
    "        self.noaaStationLat     = 0.0\n",
    "        self.noaaStationLng     = 0.0\n",
    "        self.openAqSensorIDs       = []\n",
    "        \n",
    "        self.aqParamTarget      = aqParamTarget\n",
    "        \n",
    "        if unhealthyThreshold and unhealthyThreshold > 0.0:\n",
    "            self.unhealthyThreshold = unhealthyThreshold\n",
    "        else:\n",
    "            self.unhealthyThreshold = self.aqParamTarget.unhealthyThresholdDefault\n",
    "        \n",
    "        self.yearStart          = yearStart\n",
    "        self.yearEnd            = yearEnd\n",
    "        self.aqRadiusMiles      = aqRadiusMiles\n",
    "        self.aqRadiusMeters     = aqRadiusMiles * 1610 # Rough integer approximation is fine here.\n",
    "        \n",
    "        self.modelFolder        = \"AutogluonModels\"\n",
    "            \n",
    "    def getSummary(self):\n",
    "        return f\"Scenario: {self.name} => {self.aqParamTarget.desc} ({self.aqParamTarget.name}) with UnhealthyThreshold > {self.unhealthyThreshold} {self.aqParamTarget.unit}\"\n",
    "    \n",
    "    def getModelPath(self):\n",
    "        return f\"{self.modelFolder}/aq_{self.name}_{self.yearStart}-{self.yearEnd}/\"\n",
    "    \n",
    "    def updateNoaaStationLatLng(self, noaagsod_df_row):\n",
    "        # Use a NOAA row to set Lat+Lng values used for the OpenAQ API requests...\n",
    "        if(noaagsod_df_row is not None and noaagsod_df_row['LATITUDE'] and noaagsod_df_row['LONGITUDE']):\n",
    "            self.noaaStationLat = noaagsod_df_row['LATITUDE']\n",
    "            self.noaaStationLng = noaagsod_df_row['LONGITUDE']\n",
    "            print(f\"NOAA Station Lat,Lng Updated for Scenario: {self.name} => {self.noaaStationLat},{self.noaaStationLng}\")\n",
    "        else:\n",
    "            print(\"NOAA Station Lat,Lng COULD NOT BE UPDATED.\")\n",
    "    \n",
    "    def isValid(self):\n",
    "        if(self is not None and self.aqParamTarget is not None and\n",
    "           self.yearStart > 0 and self.yearEnd > 0 and self.yearEnd >= self.yearStart and \n",
    "           self.aqRadiusMiles > 0 and self.aqRadiusMeters > 0 and self.unhealthyThreshold > 0.0 and \n",
    "           len(self.name) > 0 and len(self.noaaStationID) > 0):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    def toJSON(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=2)\n",
    "\n",
    "# class AQbyWeatherApp => Main app class with settings, AQParams, AQScenarios, and data access methods...\n",
    "class AQbyWeatherApp:\n",
    "    def __init__(self, mlTargetLabel='isUnhealthy', mlEvalMetric='accuracy', mlTimeLimitSecs=None):\n",
    "        self.mlTargetLabel   = mlTargetLabel\n",
    "        self.mlEvalMetric    = mlEvalMetric\n",
    "        self.mlTimeLimitSecs = mlTimeLimitSecs\n",
    "        self.mlIgnoreColumns = ['DATE','NAME','LATITUDE','LONGITUDE','day','avg']\n",
    "        \n",
    "        self.defaultColumnsNOAA   = ['DATE','NAME','LATITUDE','LONGITUDE',\n",
    "                                     'DEWP','WDSP','MAX','MIN','PRCP','MONTH'] # Default relevant NOAA columns\n",
    "        # self.defaultColumnsOpenAQ = ['summary']       # Default relevant OpenAQ columns\n",
    "        \n",
    "        self.aqParams    = {} # A list to save AQParam objects\n",
    "        self.aqScenarios = {} # A list to save AQScenario objects\n",
    "        \n",
    "        self.selectedScenario = None\n",
    "    \n",
    "    def addAQParam(self, aqParam):\n",
    "        if aqParam and aqParam.isValid():\n",
    "            self.aqParams[aqParam.name] = aqParam\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def addAQScenario(self, aqScenario):\n",
    "        if aqScenario and aqScenario.isValid():\n",
    "            self.aqScenarios[aqScenario.name] = aqScenario\n",
    "            if(self.selectedScenario is None):\n",
    "                self.selectedScenario = self.aqScenarios[next(iter(self.aqScenarios))] # Default selectedScenario to 1st item.\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def getFilenameNOAA(self):\n",
    "        if self and self.selectedScenario and self.selectedScenario.isValid():\n",
    "            return f\"dataNOAA_{self.selectedScenario.name}_{self.selectedScenario.yearStart}-{self.selectedScenario.yearEnd}_{self.selectedScenario.noaaStationID}.csv\"\n",
    "        else:\n",
    "            return \"\"\n",
    "    \n",
    "    def getFilenameOpenAQ(self):\n",
    "        if self and self.selectedScenario and self.selectedScenario.isValid() and len(self.selectedScenario.openAqSensorIDs) > 0:\n",
    "            idString = \"\"\n",
    "            for i in range(0, len(self.selectedScenario.openAqSensorIDs)):\n",
    "                if i > 5:\n",
    "                    break\n",
    "                idString = idString + str(self.selectedScenario.openAqSensorIDs[i]) + \"-\"\n",
    "            idString = idString[:-1]\n",
    "            return f\"dataOpenAQ_{self.selectedScenario.name}_{self.selectedScenario.yearStart}-{self.selectedScenario.yearEnd}_{idString}.csv\"\n",
    "        else:\n",
    "            return \"\"\n",
    "    \n",
    "    def getFilenameOther(self, prefix):\n",
    "        if self and self.selectedScenario and self.selectedScenario.isValid():\n",
    "            return f\"{prefix}_{self.selectedScenario.name}_{self.selectedScenario.yearStart}-{self.selectedScenario.yearEnd}.csv\"\n",
    "    \n",
    "    def getNoaaDataFrame(self):\n",
    "        # ASDI Dataset Name: NOAA GSOD\n",
    "        # ASDI Dataset URL : https://registry.opendata.aws/noaa-gsod/\n",
    "        # NOAA GSOD README : https://www.ncei.noaa.gov/data/global-summary-of-the-day/doc/readme.txt\n",
    "        # NOAA GSOD data in S3 is organized by year and Station ID values, so this is straight-forward\n",
    "        # Example S3 path format => s3://noaa-gsod-pds/{yyyy}/{stationid}.csv\n",
    "        # Let's start with a new DataFrame and load it from a local CSV or the NOAA data source...\n",
    "        noaagsod_df = pd.DataFrame()\n",
    "        filenameNOAA = self.getFilenameNOAA()\n",
    "\n",
    "        if os.path.exists(filenameNOAA):\n",
    "            # Use local data file already accessed + prepared...\n",
    "            print('Loading NOAA GSOD data from local file: ', filenameNOAA)\n",
    "            noaagsod_df = pd.read_csv(filenameNOAA)\n",
    "        else:\n",
    "            # Access + prepare data and save to a local data file...\n",
    "            noaagsod_bucket = 'noaa-gsod-pds'\n",
    "            print(f'Accessing and preparing data from ASDI-hosted NOAA GSOD dataset in Amazon S3 (bucket: {noaagsod_bucket})...')\n",
    "            s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "            for year in range(self.selectedScenario.yearStart, self.selectedScenario.yearEnd + 1):\n",
    "                key = f'{year}/{self.selectedScenario.noaaStationID}.csv'                                    # Compute the key to get\n",
    "                csv_obj = s3.get_object(Bucket=noaagsod_bucket, Key=key)                                     # Get the S3 object\n",
    "                csv_string = csv_obj['Body'].read().decode('utf-8')                                          # Read object contents to a string\n",
    "                noaagsod_df = pd.concat([noaagsod_df, pd.read_csv(StringIO(csv_string))], ignore_index=True) # Use the string to build the DataFrame\n",
    "\n",
    "            # It may be true that Month affects air quality (ie: seasonal considerations; tends to have correlation for certain areas)\n",
    "            # Extract date components for seasonality\n",
    "            noaagsod_df['MONTH'] = pd.to_datetime(noaagsod_df['DATE']).dt.month\n",
    "            noaagsod_df['DAYOFWEEK'] = pd.to_datetime(noaagsod_df['DATE']).dt.dayofweek\n",
    "            noaagsod_df['SEASON'] = pd.to_datetime(noaagsod_df['DATE']).dt.month.map({1: 'Winter', 2: 'Winter', 3: 'Spring', \n",
    "                                                                                      4: 'Spring', 5: 'Spring', 6: 'Summer',\n",
    "                                                                                      7: 'Summer', 8: 'Summer', 9: 'Fall', \n",
    "                                                                                      10: 'Fall', 11: 'Fall', 12: 'Winter'})\n",
    "            \n",
    "            # Calculate temperature differences and averages\n",
    "            noaagsod_df['TEMP_RANGE'] = noaagsod_df['MAX'] - noaagsod_df['MIN']\n",
    "            noaagsod_df['TEMP_AVG'] = (noaagsod_df['MAX'] + noaagsod_df['MIN']) / 2\n",
    "            \n",
    "            # Create interaction features\n",
    "            noaagsod_df['TEMP_DEWP_DIFF'] = noaagsod_df['TEMP_AVG'] - noaagsod_df['DEWP']\n",
    "            noaagsod_df['WDSP_TEMP'] = noaagsod_df['WDSP'] * noaagsod_df['TEMP_AVG']\n",
    "\n",
    "            # Trim down to the desired key columns... (do this last in case engineered columns are to be removed)\n",
    "            # noaagsod_df = noaagsod_df[self.defaultColumnsNOAA]\n",
    "            \n",
    "        return noaagsod_df\n",
    "        \n",
    "    def getOpenAqDataFrame(self):\n",
    "        # ASDI Dataset Name: OpenAQ\n",
    "        # ASDI Dataset URL : https://registry.opendata.aws/openaq/\n",
    "        # OpenAQ API Docs  : https://docs.openaq.org/\n",
    "        # OpenAQ S3 data is only organized by date folders, so each folder is large and contains all stations.\n",
    "        # Because of this, it's better to query ASDI OpenAQ data using the CloudFront-hosted API.\n",
    "        # Note that some days may not have values and will get filtered out via an INNER JOIN later.\n",
    "        # Let's start with a new DataFrame and load it from a local CSV or the NOAA data source...\n",
    "        aq_df = pd.DataFrame()\n",
    "        aq_reqUrlBase = \"https://api.openaq.org/v3\" # OpenAQ ASDI API Endpoint URL Base\n",
    "        print(f\"API Key: {api_key}\")\n",
    "        headers = {\n",
    "            'accept': 'application/json',\n",
    "            'x-api-key': api_key\n",
    "        }\n",
    "\n",
    "        if self.selectedScenario.noaaStationLat == 0.0 or self.selectedScenario.noaaStationLng == 0.0:\n",
    "            print(\"NOAA Station Lat/Lng NOT DEFINED. CANNOT PROCEED\")\n",
    "            return aq_df\n",
    "        \n",
    "        if len(self.selectedScenario.openAqSensorIDs) == 0:\n",
    "            # Find OpenAQ sensors near the NOAA station location\n",
    "            print('Finding OpenAQ sensors near NOAA station location...')\n",
    "            \n",
    "            # Query OpenAQ locations API with coordinates\n",
    "            aq_reqParams = {\n",
    "                'coordinates': f\"{self.selectedScenario.noaaStationLat},{self.selectedScenario.noaaStationLng}\",\n",
    "                'radius': 25000, # 25km radius\n",
    "                'parameter': self.selectedScenario.aqParamTarget.name,\n",
    "                'limit': 100\n",
    "            }\n",
    "            \n",
    "            aq_resp = requests.get(aq_reqUrlBase + \"/locations\", params=aq_reqParams, headers=headers)\n",
    "            aq_data = aq_resp.json()\n",
    "            \n",
    "            if 'results' in aq_data:\n",
    "                for location in aq_data['results']:\n",
    "                    # Check each location's sensors for our target parameter\n",
    "                    for sensor in location['sensors']:\n",
    "                        if sensor['parameter']['name'] == self.selectedScenario.aqParamTarget.name:\n",
    "                            self.selectedScenario.openAqSensorIDs.append(sensor['id'])\n",
    "                            break # Only need one sensor per location\n",
    "                            \n",
    "            print(f'Found {len(self.selectedScenario.openAqSensorIDs)} OpenAQ locations with {self.selectedScenario.aqParamTarget.name} sensors')\n",
    "        \n",
    "        if len(self.selectedScenario.openAqSensorIDs) >= 1:\n",
    "            filenameOpenAQ = self.getFilenameOpenAQ()\n",
    "\n",
    "            if os.path.exists(filenameOpenAQ):\n",
    "                # Use local data file already accessed + prepared...\n",
    "                print('Loading OpenAQ data from local file: ', filenameOpenAQ)\n",
    "                aq_df = pd.read_csv(filenameOpenAQ)\n",
    "            else:\n",
    "                # Access + prepare data (NOTE: calling OpenAQ API one year at a time to avoid timeouts)\n",
    "                print('Accessing ASDI-hosted OpenAQ Measurements (HTTPS API)...')\n",
    "                \n",
    "                for year in range(self.selectedScenario.yearStart, self.selectedScenario.yearEnd + 1):\n",
    "                    for sensor_id in self.selectedScenario.openAqSensorIDs:\n",
    "                        # Get daily measurements for this sensor and year\n",
    "                        aq_reqUrl = f\"{aq_reqUrlBase}/sensors/{sensor_id}/days\"\n",
    "                        aq_reqParams = {\n",
    "                            'date_from': f'{year}-01-01',\n",
    "                            'date_to': f'{year}-12-31',\n",
    "                            'limit': 366\n",
    "                        }\n",
    "                        \n",
    "                        print(f'Fetching data for sensor {sensor_id} in {year}')\n",
    "                        aq_resp = requests.get(aq_reqUrl, params=aq_reqParams, headers=headers)\n",
    "                        aq_data = aq_resp.json()\n",
    "                        \n",
    "                        if 'results' in aq_data:\n",
    "                            for measurement in aq_data['results']:\n",
    "                                dt = datetime.strptime(measurement['period']['datetimeFrom']['utc'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                                if measurement['value'] is not None:\n",
    "                                    date_df = pd.DataFrame({'day': [dt.date()], 'avg': [measurement['value']]})\n",
    "                                    aq_df = pd.concat([aq_df, date_df], ignore_index=True)\n",
    "\n",
    "                # Group by day and calculate daily averages\n",
    "                if not aq_df.empty:\n",
    "                    aq_df = aq_df.groupby('day')['avg'].mean().reset_index()\n",
    "\n",
    "                # Perform some Label Engineering to add our binary classification label => {0=OKAY, 1=UNHEALTHY}\n",
    "                if not aq_df.empty:\n",
    "                    aq_df[self.mlTargetLabel] = np.where(aq_df['avg'] <= self.selectedScenario.unhealthyThreshold, 0, 1)\n",
    "        \n",
    "        return aq_df\n",
    "    \n",
    "    def getMergedDataFrame(self, noaagsod_df, aq_df):\n",
    "        if len(noaagsod_df) > 0 and len(aq_df) > 0:\n",
    "            # Print shapes before merge to debug\n",
    "            print(f\"NOAA GSOD shape before merge: {noaagsod_df.shape}\")\n",
    "            print(f\"AQ data shape before merge: {aq_df.shape}\")\n",
    "            print(\"\\nNOAA GSOD sample:\")\n",
    "            print(noaagsod_df.head())\n",
    "            print(\"\\nAQ data sample:\")\n",
    "            print(aq_df.head())\n",
    "            \n",
    "            merged_df = pd.merge(noaagsod_df, aq_df, how=\"inner\", left_on=\"DATE\", right_on=\"day\")\n",
    "            \n",
    "            # Print shape after merge to see if rows were lost\n",
    "            print(f\"\\nMerged shape: {merged_df.shape}\")\n",
    "            \n",
    "            if len(merged_df) == 0:\n",
    "                print(\"\\nMerge resulted in empty DataFrame. This means there are no matching dates between the two datasets.\")\n",
    "                print(\"Check that DATE and day columns have the same format (both should be datetime or string)\")\n",
    "                print(f\"DATE dtype: {noaagsod_df['DATE'].dtype}\")\n",
    "                print(f\"day dtype: {aq_df['day'].dtype}\")\n",
    "            \n",
    "            display(merged_df)\n",
    "            merged_df = merged_df.drop(columns=self.mlIgnoreColumns)\n",
    "            return merged_df\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def getConfusionMatrixData(self, cm):\n",
    "        cmData = SimpleNamespace()\n",
    "        cmData.TN = cm[0][0]\n",
    "        cmData.TP = cm[1][1]\n",
    "        cmData.FN = cm[1][0]\n",
    "        cmData.FP = cm[0][1]\n",
    "        \n",
    "        cmData.TN_Rate = cmData.TN/(cmData.TN+cmData.FP)\n",
    "        cmData.TP_Rate = cmData.TP/(cmData.TP+cmData.FN)\n",
    "        cmData.FN_Rate = cmData.FN/(cmData.FN+cmData.TP)\n",
    "        cmData.FP_Rate = cmData.FP/(cmData.FP+cmData.TN)\n",
    "        \n",
    "        cmData.TN_Output = f\"True Negatives  (TN): {cmData.TN} of {cmData.TN+cmData.FP} => {round(cmData.TN_Rate * 100, 2)}%\"\n",
    "        cmData.TP_Output = f\"True Positives  (TP): {cmData.TP} of {cmData.TP+cmData.FN} => {round(cmData.TP_Rate * 100, 2)}%\"\n",
    "        cmData.FN_Output = f\"False Negatives (FN): {cmData.FN} of {cmData.FN+cmData.TP} => {round(cmData.FN_Rate * 100, 2)}%\"\n",
    "        cmData.FP_Output = f\"False Positives (FP): {cmData.FP} of {cmData.FP+cmData.TN} => {round(cmData.FP_Rate * 100, 2)}%\"\n",
    "        \n",
    "        return cmData\n",
    "            \n",
    "print(\"Classes and Variables are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL #4: Review the pre-defined AQParams and AQScenarios in this cell. You can edit these and/or use your own...\n",
    "# AQParams are added with default thresholds, which can be overridden on a per-AQScenario basis.\n",
    "# These AQParams are based on the OpenAQ /parameters API call where isCore=true (https://api.openaq.org/v2/parameters).\n",
    "# Default thresholds where provided using data from EPA.gov (https://www.epa.gov/criteria-air-pollutants/naaqs-table).\n",
    "# Confirm and adjust params or thresholds as needed for your needs... Not for scientific or health purposes.\n",
    "\n",
    "# Instantiate main App class with explicit mlTargetLabel and mlEvalMetric provided...\n",
    "AQbyWeather = AQbyWeatherApp(mlTargetLabel='isUnhealthy', mlEvalMetric='accuracy', mlTimeLimitSecs=120)\n",
    "\n",
    "# Define and add new AQParams...\n",
    "AQbyWeather.addAQParam(AQParam( 1, \"pm10\", \"µg/m³\", 150.0, \"Particulate Matter < 10 micrometers\"))\n",
    "AQbyWeather.addAQParam(AQParam( 2, \"pm25\", \"µg/m³\",  12.0, \"Particulate Matter < 2.5 micrometers\"))\n",
    "AQbyWeather.addAQParam(AQParam( 7, \"no2\",  \"ppm\",   100.0, \"Nitrogen Dioxide\"))\n",
    "AQbyWeather.addAQParam(AQParam( 8, \"co\",   \"ppm\",     9.0, \"Carbon Monoxide\"))\n",
    "AQbyWeather.addAQParam(AQParam( 9, \"so2\",  \"ppm\",    75.0, \"Sulfur Dioxide\"))\n",
    "AQbyWeather.addAQParam(AQParam(10, \"o3\",   \"ppm\",   0.070, \"Ground Level Ozone\"))\n",
    "\n",
    "# Define available AQ Scenarios for certain locations with their associated NOAA GSOD StationID values...\n",
    "# NOAA GSOD Station Search: https://www.ncei.noaa.gov/access/search/data-search/global-summary-of-the-day\n",
    "# TODO: Someday consider how to OPTIONALLY append more scenarios via an optional JSON file\n",
    "#       (ie: without adding a dependecy outside the .ipynb file)\n",
    "# NOTE: For Ozone Scenarios, we're generally using 0.035 ppm to override the default threshold.\n",
    "AQbyWeather.addAQScenario(AQScenario(\"bakersfield\", \"72384023155\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"bakersfield\", \"72384023155\", AQbyWeather.aqParams[\"pm10\"], None)) # Attempt at pm10 prediction.\n",
    "AQbyWeather.addAQScenario(AQScenario(\"bakersfield\", \"72384023155\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"fresno\",      \"72389093193\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"fresno\",      \"72389093193\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"visalia\",     \"72389693144\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"visalia\",     \"72389693144\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"san-jose\",    \"72494693232\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"san-jose\",    \"72494693232\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"los-angeles\", \"72287493134\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"los-angeles\", \"72287493134\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"phoenix\",     \"72278023183\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"phoenix\",     \"72278023183\", AQbyWeather.aqParams[\"o3\"],  0.035))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"fairbanks\",   \"70261026411\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "AQbyWeather.addAQScenario(AQScenario(\"lahore-pk\",   \"41640099999\", AQbyWeather.aqParams[\"pm25\"], None))\n",
    "\n",
    "print(f\"AQbyWeather.aqParams: {str(len(AQbyWeather.aqParams))}\")\n",
    "print(f\"AQbyWeather.aqScenarios: {str(len(AQbyWeather.aqScenarios))} (Default Selected: {AQbyWeather.selectedScenario.name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL #5: Select a Scenario via DROP DOWN LIST to use throughout the Notebook. This will drive the ML process...\n",
    "# A default \"value\" is set to avoid issues. Change this default to run the Notebook from start-to-finish for that Scenario.\n",
    "print(\"*** CHOOSE YOUR OWN ADVENTURE HERE ***\")\n",
    "print(\"Please select a Scenario via the following drop-down-list...\")\n",
    "print(\"(NOTE: If you change Scenario, you must re-run remaining cells to see changes.)\")\n",
    "ddl = widgets.Dropdown(options=AQbyWeather.aqScenarios.keys(), \n",
    "                       value=AQbyWeather.aqScenarios[\"los-angeles_pm25\"].name) # <-- DEFAULT / FULL-RUN VALUE\n",
    "ddl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ddl.value:\n",
    "    AQbyWeather.selectedScenario = AQbyWeather.aqScenarios[ddl.value]\n",
    "    print(AQbyWeather.selectedScenario.getSummary())\n",
    "    print(AQbyWeather.selectedScenario.toJSON())\n",
    "else:\n",
    "    print(\"Please select a Scenario via the above drop-down-list.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET NOAA GSOD WEATHER DATA...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "noaagsod_df = AQbyWeather.getNoaaDataFrame()\n",
    "\n",
    "if(len(noaagsod_df) >= 1):\n",
    "    # Update NOAA Station Lat/Lng...\n",
    "    AQbyWeather.selectedScenario.updateNoaaStationLatLng(noaagsod_df.iloc[0])\n",
    "    \n",
    "    # Save DataFrame to CSV...\n",
    "    noaagsod_df.to_csv(AQbyWeather.getFilenameNOAA(), index=False)\n",
    "\n",
    "    # Output DataFrame properties...\n",
    "    print('noaagsod_df.shape =', noaagsod_df.shape)\n",
    "    display(noaagsod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET OPENAQ AIR QUALITY DAILY AVERAGES DATA...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "aq_df = AQbyWeather.getOpenAqDataFrame() # Gets nearby Location IDs THEN gets associated daily averages.\n",
    "print(aq_df)\n",
    "\n",
    "if len(aq_df) > 0:\n",
    "    # Output DataFrame properties...\n",
    "    print('aq_df.shape =', aq_df.shape)\n",
    "    display(aq_df)\n",
    "    aq_df.to_csv(AQbyWeather.getFilenameOpenAQ(), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the NOAA GSOD weather data with our OpenAQ data by DATE...\n",
    "# Perform another column drop to remove columns we don't want as features/inputs.\n",
    "# This column removal will NOT be necessary once we can use Autogluon ignore_columns param (TBD).\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "# Debug merge operation\n",
    "print(\"NOAA GSOD data shape:\", noaagsod_df.shape)\n",
    "print(\"\\nNOAA GSOD sample dates:\")\n",
    "print(noaagsod_df['DATE'].head())\n",
    "print(noaagsod_df.columns.tolist())   # list of all column names\n",
    "\n",
    "print(\"\\nOpenAQ data shape:\", aq_df.shape) \n",
    "print(\"\\nOpenAQ sample dates:\")\n",
    "print(aq_df['day'].head())\n",
    "\n",
    "# Check for date format consistency\n",
    "print(\"\\nNOAA date type:\", noaagsod_df['DATE'].dtype)\n",
    "# Convert dates to string type\n",
    "noaagsod_df['DATE'] = noaagsod_df['DATE'].astype(str)\n",
    "aq_df['day'] = aq_df['day'].astype(str)\n",
    "print(\"OpenAQ date type:\", aq_df['day'].dtype)\n",
    "print(\"NOAA date type:\", noaagsod_df['DATE'].dtype)\n",
    "\n",
    "# Attempt merge with debug info\n",
    "merged_df = AQbyWeather.getMergedDataFrame(noaagsod_df, aq_df)\n",
    "print(\"\\nMerged data shape:\", merged_df.shape)\n",
    "if(len(merged_df) > 0):\n",
    "    # Output DataFrame properties...\n",
    "    print('merged_df.shape =', merged_df.shape)\n",
    "    display(merged_df)\n",
    "    merged_df.groupby([AQbyWeather.mlTargetLabel]).size().plot(kind=\"bar\")\n",
    "    merged_df.to_csv(AQbyWeather.getFilenameOther(\"dataMERGED\"), index=False)\n",
    "\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.features.generators import PipelineFeatureGenerator, CategoryFeatureGenerator, IdentityFeatureGenerator\n",
    "from autogluon.common.features.types import R_INT, R_FLOAT\n",
    "from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
    "\n",
    "columns_to_drop=['MIN_ATTRIBUTES', 'MAX_ATTRIBUTES']\n",
    "merged_df = merged_df.drop(columns=[col for col in columns_to_drop if col in merged_df.columns])\n",
    "\n",
    "merged_df = merged_df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "auto_ml_pipeline_feature_generator = AutoMLPipelineFeatureGenerator()\n",
    "merged_df = auto_ml_pipeline_feature_generator.fit_transform(X=merged_df)\n",
    "\n",
    "print(\"\\nColumn dtypes:\")\n",
    "print(merged_df.dtypes)\n",
    "\n",
    "# Display basic statistics of the merged dataframe\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(\"\\nShape:\", merged_df.shape)\n",
    "print(\"\\nColumns:\", merged_df.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "print(merged_df.dtypes)\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(merged_df.describe())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(merged_df.isnull().sum())\n",
    "print(\"\\nValue Counts for Target Variable 'isUnhealthy':\")\n",
    "print(merged_df['isUnhealthy'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations in our merged dataframe...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "correlations = merged_df.corr()\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0, len(merged_df.columns), 1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(merged_df.columns)\n",
    "ax.set_yticklabels(merged_df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional import statements for autogluon+sklearn and split out train_df + validate_df data...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "train_df, validate_df = train_test_split(merged_df, test_size=0.25, random_state=1)\n",
    "print('Number of training samples:', len(train_df))\n",
    "print('Number of validation samples:', len(validate_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test_df data and remove the target label column...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "test_df=validate_df.drop([AQbyWeather.mlTargetLabel], axis=1)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.common import space\n",
    "\n",
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 50,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': space.Real(1e-4, 1e-2, default=1e-3, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'dropout_prob': space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "num_trials = 10  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "time_limit = 60 * 60\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}  # Refer to TabularPredictor.fit docstring for all valid values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use AutoGluon TabularPredictor to fit a model for our training data...\n",
    "display(AQbyWeather.selectedScenario.getSummary()) #Using display for consistent/sequential output order.\n",
    "predictor = TabularPredictor(label=AQbyWeather.mlTargetLabel, \n",
    "                             eval_metric=AQbyWeather.mlEvalMetric, \n",
    "                             path=AQbyWeather.selectedScenario.getModelPath())\n",
    "predictor.fit(train_data=train_df, auto_stack=True, time_limit=time_limit, hyperparameters=hyperparameters,\n",
    "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs, verbosity=3, presets='best_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframes for feature importance + model leaderboard AND get+display model evaluation...\n",
    "display(AQbyWeather.selectedScenario.getSummary()) #Using display for consistent/sequential output order.\n",
    "featureimp_df   = predictor.feature_importance(validate_df)\n",
    "leaderboard_df  = predictor.leaderboard(validate_df, silent=True)\n",
    "modelEvaluation = predictor.evaluate(validate_df, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Autogluon Individual Model Leaderboard...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "display(leaderboard_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View and Plot Feature Importance... (this various from Scenario to Scenario)\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "display(featureimp_df)\n",
    "featureimp_df.drop(columns=[\"n\"]).plot(kind=\"bar\", figsize=(12, 4), xlabel=\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load + Use Our Model (this line is unnecessary, but shows how to load a built model)...\n",
    "predictor = TabularPredictor.load(AQbyWeather.selectedScenario.getModelPath())\n",
    "\n",
    "# Make Predictions, which are saved to an array: y_pred\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "y_pred = predictor.predict(test_df)\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true label values as an array: y_true\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "y_true = validate_df[AQbyWeather.mlTargetLabel]\n",
    "display(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Confusion Matrix (CM), Get Additional CM Data, View CM...\n",
    "# Learn More: https://towardsdatascience.com/confusion-matrix-what-is-it-e859e1bbecdc\n",
    "#             https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print Confusion Matrix data...\n",
    "cmData = AQbyWeather.getConfusionMatrixData(cm)\n",
    "print(cmData.TN_Output)\n",
    "print(cmData.TP_Output)\n",
    "print(cmData.FN_Output)\n",
    "print(cmData.FP_Output)\n",
    "\n",
    "# Plot Confusion Matrix...\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "cmd.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save final results...\n",
    "print(AQbyWeather.selectedScenario.getSummary())\n",
    "resultsFile = AQbyWeather.getFilenameOther(\"dataRESULTS\")\n",
    "results_df = pd.DataFrame()\n",
    "results_df['PREDICTION'] = pd.DataFrame(y_pred)\n",
    "results_df = pd.concat([validate_df, results_df], axis=1)\n",
    "results_df.to_csv(resultsFile, index=False)\n",
    "print(f\"Results saved to {resultsFile}. DONE.\")\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
